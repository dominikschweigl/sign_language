<<<<<<< HEAD
not augmented data, but with balancing:
=======
>>>>>>> f547d8b26c7d13467fcb7bc5d329bc0f53f3e7f3

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 84.33%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 88.04%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 86.13%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.57%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.65%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 84.05%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.74%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.35%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.24%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 81.56%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.93%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 86.01%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 84.91%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 83.91%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.32%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.24%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.21%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 86.49%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 84.19%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 86.07%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.24%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.29%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.52%

ğŸ” Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 84.66%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.77%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 83.36%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 83.74%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.07%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 83.99%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 84.27%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.66%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 83.91%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.02%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 82.86%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 86.79%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 84.05%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 84.08%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 86.71%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 86.40%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 81.00%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.13%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.96%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 82.75%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.79%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.24%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.11%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 86.60%

ğŸ” Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 87.43%

<<<<<<< HEAD

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 86.24%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.38%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 82.39%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 84.60%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.35%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 83.16%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 84.19%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 83.44%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.46%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.97%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.43%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 82.25%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.16%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 82.77%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 86.60%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 81.64%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.99%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 86.79%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 84.27%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.99%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.63%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.25%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.57%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 86.07%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.27%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 83.83%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 82.61%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.19%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 82.44%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 83.38%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 82.41%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.93%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 83.80%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.63%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.96%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.16%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.85%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.13%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.27%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 84.74%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.91%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 84.46%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 82.83%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.52%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 83.30%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 83.99%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.05%

ğŸ” Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 84.41%

1. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 86.79%
2. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 86.60%
3. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 86.24%
4. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 86.07%
5. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 85.93%
6. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 85.63%
7. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 85.52%
8. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 85.46%
9. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 85.43%
10. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 85.35%
11. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 85.27%
12. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 85.27%
13. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 85.16%
14. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 85.13%
15. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.99%
16. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 84.99%
17. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.96%
18. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.91%
19. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 84.74%
20. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 84.60%
21. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.57%
22. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 84.46%
23. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 84.41%
24. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 84.38%
25. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 84.27%
26. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 84.19%
27. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.05%
28. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.99%
29. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.97%
30. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 83.85%
31. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 83.83%
32. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 83.80%
33. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.63%
34. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 83.44%
35. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 83.38%
36. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 83.30%
37. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.25%
38. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.19%
39. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 83.16%
40. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 83.16%
41. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 82.83%
42. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 82.77%
43. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 82.61%
44. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 82.44%
45. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 82.41%
46. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 82.39%
47. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 82.25%
48. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 81.64%


with augmented data:

ğŸ” Testing combination: {'lr': 0.008252553143535197, 'batch_size': 64, 'dropout': 0.26517306957493525, 'conv_channels': [16, 32, 64], 'linear_size': 128, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 2.74%

ğŸ” Testing combination: {'lr': 0.005491080462828726, 'batch_size': 64, 'dropout': 0.3717566897162151, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.99%

ğŸ” Testing combination: {'lr': 0.006785057154116505, 'batch_size': 16, 'dropout': 0.41974795194886466, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 2.94%

ğŸ” Testing combination: {'lr': 0.0018357335559105, 'batch_size': 16, 'dropout': 0.29581787387970687, 'conv_channels': [48, 96, 192], 'linear_size': 192, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.96%

ğŸ” Testing combination: {'lr': 0.009214597882685915, 'batch_size': 128, 'dropout': 0.42825058491264933, 'conv_channels': [16, 32, 64], 'linear_size': 256, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.85%

ğŸ” Testing combination: {'lr': 0.008472404786846863, 'batch_size': 64, 'dropout': 0.20687608884323744, 'conv_channels': [48, 96, 192], 'linear_size': 192, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 2.55%

ğŸ” Testing combination: {'lr': 0.0061560677355620725, 'batch_size': 16, 'dropout': 0.4566638535683986, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 3.41%

ğŸ” Testing combination: {'lr': 0.004231558445316906, 'batch_size': 128, 'dropout': 0.299500196768424, 'conv_channels': [16, 32, 64], 'linear_size': 128, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 2.82%

ğŸ” Testing combination: {'lr': 0.008781598617037548, 'batch_size': 128, 'dropout': 0.4706317380904241, 'conv_channels': [32, 64, 128], 'linear_size': 128, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.96%

ğŸ” Testing combination: {'lr': 0.0042625203246274375, 'batch_size': 128, 'dropout': 0.3193044771278613, 'conv_channels': [16, 32, 64], 'linear_size': 256, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 84.99%

ğŸ” Testing combination: {'lr': 0.001458620894753208, 'batch_size': 64, 'dropout': 0.3483392326394138, 'conv_channels': [48, 96, 192], 'linear_size': 384, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 2.19%

ğŸ” Testing combination: {'lr': 0.008842351712883797, 'batch_size': 128, 'dropout': 0.2956595185840582, 'conv_channels': [16, 32, 64], 'linear_size': 128, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 3.05%

ğŸ” Testing combination: {'lr': 0.0013443736297744924, 'batch_size': 8, 'dropout': 0.4998578352983471, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.85%

ğŸ” Testing combination: {'lr': 0.004063612008344013, 'batch_size': 64, 'dropout': 0.41778909849679546, 'conv_channels': [32, 64, 128], 'linear_size': 384, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 91.30%

ğŸ” Testing combination: {'lr': 0.0022651724318132347, 'batch_size': 8, 'dropout': 0.2992859150762729, 'conv_channels': [32, 64, 128], 'linear_size': 128, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.82%

ğŸ” Testing combination: {'lr': 0.0066553734398453615, 'batch_size': 16, 'dropout': 0.33093802584451626, 'conv_channels': [32, 64, 128], 'linear_size': 192, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 2.38%

ğŸ” Testing combination: {'lr': 0.0028308651296598203, 'batch_size': 8, 'dropout': 0.29610900518394584, 'conv_channels': [32, 64, 128], 'linear_size': 384, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.94%

ğŸ” Testing combination: {'lr': 0.004740373521024221, 'batch_size': 32, 'dropout': 0.31214006350331736, 'conv_channels': [48, 96, 192], 'linear_size': 384, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.94%

ğŸ” Testing combination: {'lr': 0.00786751593961708, 'batch_size': 8, 'dropout': 0.3924853698484403, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'sigmoid', 'epochs': 40}
âœ… Accuracy: 2.58%

ğŸ” Testing combination: {'lr': 0.007781540856414062, 'batch_size': 32, 'dropout': 0.25343884223093527, 'conv_channels': [48, 96, 192], 'linear_size': 384, 'activation': 'relu', 'epochs': 40}
âœ… Accuracy: 2.74%

ğŸ” Testing combination: {'lr': 0.00042078338960087374, 'batch_size': 32, 'dropout': 0.3204658731577415, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.2188 â€” Train Acc: 32.81%
Epoch 2/40 â€” Train Loss: 1.2821 â€” Train Acc: 56.51%
Epoch 3/40 â€” Train Loss: 1.0215 â€” Train Acc: 64.74%
Epoch 4/40 â€” Train Loss: 0.8658 â€” Train Acc: 69.55%
Epoch 5/40 â€” Train Loss: 0.7736 â€” Train Acc: 72.80%
Epoch 6/40 â€” Train Loss: 0.7094 â€” Train Acc: 74.91%
Epoch 7/40 â€” Train Loss: 0.6496 â€” Train Acc: 76.85%
Epoch 8/40 â€” Train Loss: 0.6140 â€” Train Acc: 78.32%
Epoch 9/40 â€” Train Loss: 0.5701 â€” Train Acc: 79.38%
Epoch 10/40 â€” Train Loss: 0.5416 â€” Train Acc: 80.51%
Epoch 11/40 â€” Train Loss: 0.5159 â€” Train Acc: 81.54%
Epoch 12/40 â€” Train Loss: 0.4934 â€” Train Acc: 82.49%
Epoch 13/40 â€” Train Loss: 0.4624 â€” Train Acc: 83.48%
Epoch 14/40 â€” Train Loss: 0.4537 â€” Train Acc: 83.79%
Epoch 15/40 â€” Train Loss: 0.4369 â€” Train Acc: 84.86%
Epoch 16/40 â€” Train Loss: 0.4194 â€” Train Acc: 84.90%
Epoch 17/40 â€” Train Loss: 0.4017 â€” Train Acc: 85.84%
Epoch 18/40 â€” Train Loss: 0.3890 â€” Train Acc: 86.17%
Epoch 19/40 â€” Train Loss: 0.3794 â€” Train Acc: 86.66%
Epoch 20/40 â€” Train Loss: 0.3679 â€” Train Acc: 86.84%
Epoch 21/40 â€” Train Loss: 0.3557 â€” Train Acc: 87.45%
Epoch 22/40 â€” Train Loss: 0.3629 â€” Train Acc: 87.11%
Epoch 23/40 â€” Train Loss: 0.3452 â€” Train Acc: 87.95%
Epoch 24/40 â€” Train Loss: 0.3366 â€” Train Acc: 88.14%
Epoch 25/40 â€” Train Loss: 0.3299 â€” Train Acc: 88.52%
Epoch 26/40 â€” Train Loss: 0.3235 â€” Train Acc: 88.49%
Epoch 27/40 â€” Train Loss: 0.3056 â€” Train Acc: 89.35%
Epoch 28/40 â€” Train Loss: 0.3043 â€” Train Acc: 89.25%
Epoch 29/40 â€” Train Loss: 0.3032 â€” Train Acc: 89.19%
Epoch 30/40 â€” Train Loss: 0.2992 â€” Train Acc: 89.49%
Epoch 31/40 â€” Train Loss: 0.2875 â€” Train Acc: 89.96%
Epoch 32/40 â€” Train Loss: 0.2842 â€” Train Acc: 90.01%
Epoch 33/40 â€” Train Loss: 0.2756 â€” Train Acc: 90.27%
Epoch 34/40 â€” Train Loss: 0.2683 â€” Train Acc: 90.59%
Epoch 35/40 â€” Train Loss: 0.2746 â€” Train Acc: 90.46%
Epoch 36/40 â€” Train Loss: 0.2656 â€” Train Acc: 90.87%
Epoch 37/40 â€” Train Loss: 0.2688 â€” Train Acc: 90.69%
Epoch 38/40 â€” Train Loss: 0.2644 â€” Train Acc: 90.57%
Epoch 39/40 â€” Train Loss: 0.2507 â€” Train Acc: 91.26%
Epoch 40/40 â€” Train Loss: 0.2433 â€” Train Acc: 91.38%
âœ… Accuracy: 96.62%

ğŸ” Testing combination: {'lr': 0.00015577215767958094, 'batch_size': 32, 'dropout': 0.30614472743709187, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'sigmoid', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.5960 â€” Train Acc: 2.83%
           â†’ Val Loss: 3.5795
Epoch 2/40 â€” Train Loss: 3.5817 â€” Train Acc: 2.95%
           â†’ Val Loss: 3.5800
Epoch 3/40 â€” Train Loss: 3.5799 â€” Train Acc: 3.19%
           â†’ Val Loss: 3.5794
Epoch 4/40 â€” Train Loss: 3.5782 â€” Train Acc: 3.30%
           â†’ Val Loss: 3.5729
Epoch 5/40 â€” Train Loss: 3.4108 â€” Train Acc: 7.69%
           â†’ Val Loss: 3.1415
Epoch 6/40 â€” Train Loss: 3.0373 â€” Train Acc: 15.76%
           â†’ Val Loss: 2.8732
Epoch 7/40 â€” Train Loss: 2.8584 â€” Train Acc: 19.01%
           â†’ Val Loss: 2.7144
Epoch 8/40 â€” Train Loss: 2.7421 â€” Train Acc: 20.93%
           â†’ Val Loss: 2.5749
Epoch 9/40 â€” Train Loss: 2.6601 â€” Train Acc: 22.98%
           â†’ Val Loss: 2.4934
Epoch 10/40 â€” Train Loss: 2.5879 â€” Train Acc: 24.48%
           â†’ Val Loss: 2.3980
Epoch 11/40 â€” Train Loss: 2.5170 â€” Train Acc: 26.20%
           â†’ Val Loss: 2.3231
Epoch 12/40 â€” Train Loss: 2.4655 â€” Train Acc: 27.69%
           â†’ Val Loss: 2.2506
Epoch 13/40 â€” Train Loss: 2.4127 â€” Train Acc: 27.96%
           â†’ Val Loss: 2.1797
Epoch 14/40 â€” Train Loss: 2.3731 â€” Train Acc: 28.50%
           â†’ Val Loss: 2.1628
Epoch 15/40 â€” Train Loss: 2.3282 â€” Train Acc: 30.37%
           â†’ Val Loss: 2.0843
Epoch 16/40 â€” Train Loss: 2.2997 â€” Train Acc: 30.70%
           â†’ Val Loss: 2.0548
Epoch 17/40 â€” Train Loss: 2.2678 â€” Train Acc: 31.48%
           â†’ Val Loss: 2.0358
Epoch 18/40 â€” Train Loss: 2.2404 â€” Train Acc: 32.31%
           â†’ Val Loss: 1.9847


ğŸ” Testing combination: {'lr': 0.000463246648991257, 'batch_size': 32, 'dropout': 0.45530686154029965, 'conv_channels': [32, 64, 128], 'linear_size': 256, 'activation': 'sigmoid', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.6352 â€” Train Acc: 2.96%
           â†’ Val Loss: 3.5909
Epoch 2/40 â€” Train Loss: 3.6211 â€” Train Acc: 2.84%
           â†’ Val Loss: 3.5885
Epoch 3/40 â€” Train Loss: 3.6107 â€” Train Acc: 3.04%
           â†’ Val Loss: 3.5934
Epoch 4/40 â€” Train Loss: 3.6053 â€” Train Acc: 3.10%
           â†’ Val Loss: 3.5817
Epoch 5/40 â€” Train Loss: 3.6023 â€” Train Acc: 2.86%
           â†’ Val Loss: 3.5878
Epoch 6/40 â€” Train Loss: 3.6013 â€” Train Acc: 2.93%
           â†’ Val Loss: 3.5880
â¹ï¸ Early stopping at epoch 6
âœ… Accuracy: 2.96%

ğŸ” Testing combination: {'lr': 0.0002400641350354702, 'batch_size': 64, 'dropout': 0.36043523654320486, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.1815 â€” Train Acc: 35.34%
           â†’ Val Loss: 1.0072
Epoch 2/40 â€” Train Loss: 1.1915 â€” Train Acc: 60.82%
           â†’ Val Loss: 0.6146
Epoch 3/40 â€” Train Loss: 0.8900 â€” Train Acc: 69.99%
           â†’ Val Loss: 0.4220
Epoch 4/40 â€” Train Loss: 0.7344 â€” Train Acc: 74.71%
           â†’ Val Loss: 0.3502
Epoch 5/40 â€” Train Loss: 0.6451 â€” Train Acc: 77.37%
           â†’ Val Loss: 0.3133
Epoch 6/40 â€” Train Loss: 0.5709 â€” Train Acc: 79.74%
           â†’ Val Loss: 0.2716
Epoch 7/40 â€” Train Loss: 0.5248 â€” Train Acc: 81.66%
           â†’ Val Loss: 0.2451
Epoch 8/40 â€” Train Loss: 0.4900 â€” Train Acc: 82.54%
           â†’ Val Loss: 0.2349
Epoch 9/40 â€” Train Loss: 0.4519 â€” Train Acc: 83.88%
           â†’ Val Loss: 0.2044
Epoch 10/40 â€” Train Loss: 0.4170 â€” Train Acc: 85.40%
           â†’ Val Loss: 0.1934
Epoch 11/40 â€” Train Loss: 0.3957 â€” Train Acc: 86.12%
           â†’ Val Loss: 0.1706
Epoch 12/40 â€” Train Loss: 0.3821 â€” Train Acc: 86.40%
           â†’ Val Loss: 0.1679
Epoch 13/40 â€” Train Loss: 0.3547 â€” Train Acc: 87.23%
           â†’ Val Loss: 0.1586
Epoch 14/40 â€” Train Loss: 0.3526 â€” Train Acc: 87.59%
           â†’ Val Loss: 0.1494
Epoch 15/40 â€” Train Loss: 0.3273 â€” Train Acc: 88.58%
           â†’ Val Loss: 0.1585
Epoch 16/40 â€” Train Loss: 0.3134 â€” Train Acc: 88.67%
           â†’ Val Loss: 0.1465
Epoch 17/40 â€” Train Loss: 0.3016 â€” Train Acc: 89.45%
           â†’ Val Loss: 0.1499
Epoch 18/40 â€” Train Loss: 0.2944 â€” Train Acc: 89.74%
           â†’ Val Loss: 0.1312
Epoch 19/40 â€” Train Loss: 0.2878 â€” Train Acc: 89.86%
           â†’ Val Loss: 0.1284
Epoch 20/40 â€” Train Loss: 0.2617 â€” Train Acc: 90.94%
           â†’ Val Loss: 0.1137
Epoch 21/40 â€” Train Loss: 0.2593 â€” Train Acc: 90.92%
           â†’ Val Loss: 0.1186
Epoch 22/40 â€” Train Loss: 0.2549 â€” Train Acc: 90.97%
           â†’ Val Loss: 0.0995
Epoch 23/40 â€” Train Loss: 0.2518 â€” Train Acc: 91.27%
           â†’ Val Loss: 0.1001
Epoch 24/40 â€” Train Loss: 0.2435 â€” Train Acc: 91.56%
           â†’ Val Loss: 0.1036
Epoch 25/40 â€” Train Loss: 0.2382 â€” Train Acc: 91.57%
           â†’ Val Loss: 0.1034
Epoch 26/40 â€” Train Loss: 0.2263 â€” Train Acc: 92.25%
           â†’ Val Loss: 0.0986
Epoch 27/40 â€” Train Loss: 0.2268 â€” Train Acc: 92.28%
           â†’ Val Loss: 0.0959
â¹ï¸ Early stopping at epoch 27
âœ… Accuracy: 96.59%

ğŸ” Testing combination: {'lr': 0.0013453987202164453, 'batch_size': 8, 'dropout': 0.22573386745693555, 'conv_channels': [32, 64, 128], 'linear_size': 128, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.2366 â€” Train Acc: 30.34%
           â†’ Val Loss: 1.3291
Epoch 2/40 â€” Train Loss: 1.5121 â€” Train Acc: 48.82%
           â†’ Val Loss: 1.0453
Epoch 3/40 â€” Train Loss: 1.3067 â€” Train Acc: 55.32%
           â†’ Val Loss: 0.8092
Epoch 4/40 â€” Train Loss: 1.1980 â€” Train Acc: 58.65%
           â†’ Val Loss: 0.7655
Epoch 5/40 â€” Train Loss: 1.1284 â€” Train Acc: 61.02%
           â†’ Val Loss: 0.6379
Epoch 6/40 â€” Train Loss: 1.0611 â€” Train Acc: 63.16%
           â†’ Val Loss: 0.6720
Epoch 7/40 â€” Train Loss: 1.0165 â€” Train Acc: 64.58%
           â†’ Val Loss: 0.6161
Epoch 8/40 â€” Train Loss: 0.9779 â€” Train Acc: 65.31%
           â†’ Val Loss: 0.6178
Epoch 9/40 â€” Train Loss: 0.9435 â€” Train Acc: 66.83%
           â†’ Val Loss: 0.5276
Epoch 10/40 â€” Train Loss: 0.9327 â€” Train Acc: 67.32%
           â†’ Val Loss: 0.5140
Epoch 11/40 â€” Train Loss: 0.9115 â€” Train Acc: 68.35%
           â†’ Val Loss: 0.5268
Epoch 12/40 â€” Train Loss: 0.8814 â€” Train Acc: 68.96%
           â†’ Val Loss: 0.5197
Epoch 13/40 â€” Train Loss: 0.8758 â€” Train Acc: 69.29%
           â†’ Val Loss: 0.4843
Epoch 14/40 â€” Train Loss: 0.8515 â€” Train Acc: 70.16%
           â†’ Val Loss: 0.4684
Epoch 15/40 â€” Train Loss: 0.8371 â€” Train Acc: 70.66%
           â†’ Val Loss: 0.4853
Epoch 16/40 â€” Train Loss: 0.8268 â€” Train Acc: 71.03%
           â†’ Val Loss: 0.4584
Epoch 17/40 â€” Train Loss: 0.8120 â€” Train Acc: 71.68%
           â†’ Val Loss: 0.4545
Epoch 18/40 â€” Train Loss: 0.8034 â€” Train Acc: 71.97%
           â†’ Val Loss: 0.4458
Epoch 19/40 â€” Train Loss: 0.7892 â€” Train Acc: 72.51%
           â†’ Val Loss: 0.4682
Epoch 20/40 â€” Train Loss: 0.7856 â€” Train Acc: 72.77%
           â†’ Val Loss: 0.4396
Epoch 21/40 â€” Train Loss: 0.7768 â€” Train Acc: 73.00%
           â†’ Val Loss: 0.4251
Epoch 22/40 â€” Train Loss: 0.7689 â€” Train Acc: 73.38%
           â†’ Val Loss: 0.3938
Epoch 23/40 â€” Train Loss: 0.7685 â€” Train Acc: 73.31%
           â†’ Val Loss: 0.4084
Epoch 24/40 â€” Train Loss: 0.7578 â€” Train Acc: 73.36%
           â†’ Val Loss: 0.4371
Epoch 25/40 â€” Train Loss: 0.7550 â€” Train Acc: 73.42%
           â†’ Val Loss: 0.4805
Epoch 26/40 â€” Train Loss: 0.7556 â€” Train Acc: 73.68%
           â†’ Val Loss: 0.3948
Epoch 27/40 â€” Train Loss: 0.7400 â€” Train Acc: 74.44%
           â†’ Val Loss: 0.4120
â¹ï¸ Early stopping at epoch 27
âœ… Accuracy: 85.24%

ğŸ” Testing combination: {'lr': 0.002004622569625198, 'batch_size': 32, 'dropout': 0.3095778760666471, 'conv_channels': [32, 64, 128], 'linear_size': 192, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.1639 â€” Train Acc: 32.74%
           â†’ Val Loss: 1.1874
Epoch 2/40 â€” Train Loss: 1.4221 â€” Train Acc: 51.38%
           â†’ Val Loss: 0.8579
Epoch 3/40 â€” Train Loss: 1.2308 â€” Train Acc: 57.31%
           â†’ Val Loss: 0.6947
Epoch 4/40 â€” Train Loss: 1.1168 â€” Train Acc: 61.16%
           â†’ Val Loss: 0.6093
Epoch 5/40 â€” Train Loss: 1.0284 â€” Train Acc: 63.98%
           â†’ Val Loss: 0.5772
Epoch 6/40 â€” Train Loss: 0.9774 â€” Train Acc: 65.89%
           â†’ Val Loss: 0.5180
Epoch 7/40 â€” Train Loss: 0.9318 â€” Train Acc: 67.50%
           â†’ Val Loss: 0.5013
Epoch 8/40 â€” Train Loss: 0.8917 â€” Train Acc: 68.35%
           â†’ Val Loss: 0.4394
Epoch 9/40 â€” Train Loss: 0.8550 â€” Train Acc: 69.87%
           â†’ Val Loss: 0.4474
Epoch 10/40 â€” Train Loss: 0.8313 â€” Train Acc: 70.93%
           â†’ Val Loss: 0.4269
Epoch 11/40 â€” Train Loss: 0.8135 â€” Train Acc: 71.44%
           â†’ Val Loss: 0.4215
Epoch 12/40 â€” Train Loss: 0.7825 â€” Train Acc: 71.87%
           â†’ Val Loss: 0.3863
Epoch 13/40 â€” Train Loss: 0.7646 â€” Train Acc: 73.00%
           â†’ Val Loss: 0.3984
Epoch 14/40 â€” Train Loss: 0.7514 â€” Train Acc: 73.37%
           â†’ Val Loss: 0.3868
Epoch 15/40 â€” Train Loss: 0.7468 â€” Train Acc: 73.72%
           â†’ Val Loss: 0.3424
Epoch 16/40 â€” Train Loss: 0.7267 â€” Train Acc: 74.26%
           â†’ Val Loss: 0.3716
Epoch 17/40 â€” Train Loss: 0.7119 â€” Train Acc: 74.78%
           â†’ Val Loss: 0.3845
Epoch 18/40 â€” Train Loss: 0.7033 â€” Train Acc: 74.97%
           â†’ Val Loss: 0.3302
Epoch 19/40 â€” Train Loss: 0.6971 â€” Train Acc: 75.60%
           â†’ Val Loss: 0.3361
Epoch 20/40 â€” Train Loss: 0.6914 â€” Train Acc: 75.59%
           â†’ Val Loss: 0.3291
Epoch 21/40 â€” Train Loss: 0.6863 â€” Train Acc: 75.68%
           â†’ Val Loss: 0.3342
Epoch 22/40 â€” Train Loss: 0.6693 â€” Train Acc: 76.19%
           â†’ Val Loss: 0.3279
Epoch 23/40 â€” Train Loss: 0.6595 â€” Train Acc: 76.61%
           â†’ Val Loss: 0.3101
Epoch 24/40 â€” Train Loss: 0.6682 â€” Train Acc: 76.38%
           â†’ Val Loss: 0.3308
Epoch 25/40 â€” Train Loss: 0.6599 â€” Train Acc: 76.73%
           â†’ Val Loss: 0.3072
Epoch 26/40 â€” Train Loss: 0.6489 â€” Train Acc: 77.36%
           â†’ Val Loss: 0.3016
Epoch 27/40 â€” Train Loss: 0.6434 â€” Train Acc: 77.32%
           â†’ Val Loss: 0.3056
Epoch 28/40 â€” Train Loss: 0.6493 â€” Train Acc: 76.94%
           â†’ Val Loss: 0.3119
â¹ï¸ Early stopping at epoch 28
âœ… Accuracy: 88.37%

ğŸ” Testing combination: {'lr': 0.0027585671686901204, 'batch_size': 8, 'dropout': 0.4423750544646695, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'sigmoid', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.7299 â€” Train Acc: 2.73%
           â†’ Val Loss: 3.6657
Epoch 2/40 â€” Train Loss: 3.7294 â€” Train Acc: 2.92%
           â†’ Val Loss: 3.6574
Epoch 3/40 â€” Train Loss: 3.7286 â€” Train Acc: 2.95%
           â†’ Val Loss: 3.6365
Epoch 4/40 â€” Train Loss: 3.7256 â€” Train Acc: 2.75%
           â†’ Val Loss: 3.6985
Epoch 5/40 â€” Train Loss: 3.7289 â€” Train Acc: 2.92%
           â†’ Val Loss: 3.6749
Epoch 6/40 â€” Train Loss: 3.7265 â€” Train Acc: 3.01%
           â†’ Val Loss: 3.6540
Epoch 7/40 â€” Train Loss: 3.7274 â€” Train Acc: 2.98%
           â†’ Val Loss: 3.6824
Epoch 8/40 â€” Train Loss: 3.7298 â€” Train Acc: 2.91%
           â†’ Val Loss: 3.7322
â¹ï¸ Early stopping at epoch 8
âœ… Accuracy: 2.52%

ğŸ” Testing combination: {'lr': 0.00021806877744184937, 'batch_size': 64, 'dropout': 0.20619482992617447, 'conv_channels': [32, 64, 128], 'linear_size': 384, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.0894 â€” Train Acc: 37.89%
           â†’ Val Loss: 0.9811
Epoch 2/40 â€” Train Loss: 1.0463 â€” Train Acc: 65.42%
           â†’ Val Loss: 0.5687
Epoch 3/40 â€” Train Loss: 0.7479 â€” Train Acc: 74.50%
           â†’ Val Loss: 0.4105
Epoch 4/40 â€” Train Loss: 0.5969 â€” Train Acc: 79.31%
           â†’ Val Loss: 0.3537
Epoch 5/40 â€” Train Loss: 0.5054 â€” Train Acc: 82.33%
           â†’ Val Loss: 0.2613
Epoch 6/40 â€” Train Loss: 0.4537 â€” Train Acc: 84.05%
           â†’ Val Loss: 0.2423
Epoch 7/40 â€” Train Loss: 0.4073 â€” Train Acc: 85.80%
           â†’ Val Loss: 0.2294
Epoch 8/40 â€” Train Loss: 0.3802 â€” Train Acc: 86.55%
           â†’ Val Loss: 0.2082
Epoch 9/40 â€” Train Loss: 0.3477 â€” Train Acc: 87.83%
           â†’ Val Loss: 0.1854
Epoch 10/40 â€” Train Loss: 0.3148 â€” Train Acc: 88.92%
           â†’ Val Loss: 0.1736
Epoch 11/40 â€” Train Loss: 0.3028 â€” Train Acc: 89.37%
           â†’ Val Loss: 0.1714
Epoch 12/40 â€” Train Loss: 0.2848 â€” Train Acc: 90.22%
           â†’ Val Loss: 0.1515
Epoch 13/40 â€” Train Loss: 0.2659 â€” Train Acc: 90.73%
           â†’ Val Loss: 0.1616
Epoch 14/40 â€” Train Loss: 0.2553 â€” Train Acc: 91.11%
           â†’ Val Loss: 0.1382
Epoch 15/40 â€” Train Loss: 0.2483 â€” Train Acc: 91.25%
           â†’ Val Loss: 0.1513
Epoch 16/40 â€” Train Loss: 0.2247 â€” Train Acc: 92.10%
           â†’ Val Loss: 0.1205
Epoch 17/40 â€” Train Loss: 0.2296 â€” Train Acc: 92.11%
           â†’ Val Loss: 0.1273
Epoch 18/40 â€” Train Loss: 0.2069 â€” Train Acc: 92.51%
           â†’ Val Loss: 0.1195
Epoch 19/40 â€” Train Loss: 0.2061 â€” Train Acc: 92.93%
           â†’ Val Loss: 0.1086
Epoch 20/40 â€” Train Loss: 0.1943 â€” Train Acc: 93.43%
           â†’ Val Loss: 0.1042
Epoch 21/40 â€” Train Loss: 0.1880 â€” Train Acc: 93.41%
           â†’ Val Loss: 0.1146
Epoch 22/40 â€” Train Loss: 0.1902 â€” Train Acc: 93.21%
           â†’ Val Loss: 0.1171
Epoch 23/40 â€” Train Loss: 0.1805 â€” Train Acc: 93.79%
           â†’ Val Loss: 0.1001
Epoch 24/40 â€” Train Loss: 0.1759 â€” Train Acc: 93.98%
           â†’ Val Loss: 0.0958
Epoch 25/40 â€” Train Loss: 0.1675 â€” Train Acc: 94.33%
           â†’ Val Loss: 0.0934
Epoch 26/40 â€” Train Loss: 0.1666 â€” Train Acc: 94.40%
           â†’ Val Loss: 0.1124
Epoch 27/40 â€” Train Loss: 0.1554 â€” Train Acc: 94.61%
           â†’ Val Loss: 0.1137
Epoch 28/40 â€” Train Loss: 0.1527 â€” Train Acc: 94.69%
           â†’ Val Loss: 0.0912
Epoch 29/40 â€” Train Loss: 0.1546 â€” Train Acc: 94.81%
           â†’ Val Loss: 0.0831
Epoch 30/40 â€” Train Loss: 0.1512 â€” Train Acc: 94.82%
           â†’ Val Loss: 0.0949
Epoch 31/40 â€” Train Loss: 0.1488 â€” Train Acc: 94.93%
           â†’ Val Loss: 0.0761
Epoch 32/40 â€” Train Loss: 0.1382 â€” Train Acc: 95.29%
           â†’ Val Loss: 0.0812
Epoch 33/40 â€” Train Loss: 0.1373 â€” Train Acc: 95.30%
           â†’ Val Loss: 0.0865
Epoch 34/40 â€” Train Loss: 0.1351 â€” Train Acc: 95.51%
           â†’ Val Loss: 0.0763
â¹ï¸ Early stopping at epoch 34
âœ… Accuracy: 96.84%

ğŸ” Testing combination: {'lr': 0.002405509739758666, 'batch_size': 128, 'dropout': 0.49569494612334025, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.5947 â€” Train Acc: 23.23%
           â†’ Val Loss: 1.3891
Epoch 2/40 â€” Train Loss: 1.6178 â€” Train Acc: 46.36%
           â†’ Val Loss: 0.9914
Epoch 3/40 â€” Train Loss: 1.3825 â€” Train Acc: 52.93%
           â†’ Val Loss: 0.7492
Epoch 4/40 â€” Train Loss: 1.2327 â€” Train Acc: 57.46%
           â†’ Val Loss: 0.6404
Epoch 5/40 â€” Train Loss: 1.1415 â€” Train Acc: 60.75%
           â†’ Val Loss: 0.5870
Epoch 6/40 â€” Train Loss: 1.0622 â€” Train Acc: 63.27%
           â†’ Val Loss: 0.5276
Epoch 7/40 â€” Train Loss: 1.0042 â€” Train Acc: 65.06%
           â†’ Val Loss: 0.5315
Epoch 8/40 â€” Train Loss: 0.9549 â€” Train Acc: 66.60%
           â†’ Val Loss: 0.4921
Epoch 9/40 â€” Train Loss: 0.9183 â€” Train Acc: 67.71%
           â†’ Val Loss: 0.4424
Epoch 10/40 â€” Train Loss: 0.8933 â€” Train Acc: 68.64%
           â†’ Val Loss: 0.4063
Epoch 11/40 â€” Train Loss: 0.8676 â€” Train Acc: 69.72%
           â†’ Val Loss: 0.4038
Epoch 12/40 â€” Train Loss: 0.8473 â€” Train Acc: 70.18%
           â†’ Val Loss: 0.4074
Epoch 13/40 â€” Train Loss: 0.8242 â€” Train Acc: 71.08%
           â†’ Val Loss: 0.3814
Epoch 14/40 â€” Train Loss: 0.8010 â€” Train Acc: 71.81%
           â†’ Val Loss: 0.3458
Epoch 15/40 â€” Train Loss: 0.7834 â€” Train Acc: 72.46%
           â†’ Val Loss: 0.3639
Epoch 16/40 â€” Train Loss: 0.7636 â€” Train Acc: 72.82%
           â†’ Val Loss: 0.3422
Epoch 17/40 â€” Train Loss: 0.7580 â€” Train Acc: 73.18%
           â†’ Val Loss: 0.3302
Epoch 18/40 â€” Train Loss: 0.7465 â€” Train Acc: 73.90%
           â†’ Val Loss: 0.3370
Epoch 19/40 â€” Train Loss: 0.7408 â€” Train Acc: 73.52%
           â†’ Val Loss: 0.3003
Epoch 20/40 â€” Train Loss: 0.7212 â€” Train Acc: 74.60%
           â†’ Val Loss: 0.3130
Epoch 21/40 â€” Train Loss: 0.7172 â€” Train Acc: 74.61%
           â†’ Val Loss: 0.3104
Epoch 22/40 â€” Train Loss: 0.6995 â€” Train Acc: 75.27%
           â†’ Val Loss: 0.3007
Epoch 23/40 â€” Train Loss: 0.6935 â€” Train Acc: 75.62%
           â†’ Val Loss: 0.3086
Epoch 24/40 â€” Train Loss: 0.6849 â€” Train Acc: 75.70%
           â†’ Val Loss: 0.2920
â¹ï¸ Early stopping at epoch 24
âœ… Accuracy: 89.03%

ğŸ” Testing combination: {'lr': 0.00010197103401578104, 'batch_size': 64, 'dropout': 0.34769106086287993, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.1843 â€” Train Acc: 10.99%
           â†’ Val Loss: 2.5224
Epoch 2/40 â€” Train Loss: 2.5680 â€” Train Acc: 23.91%
           â†’ Val Loss: 1.9728
Epoch 3/40 â€” Train Loss: 2.1544 â€” Train Acc: 33.86%
           â†’ Val Loss: 1.5043
Epoch 4/40 â€” Train Loss: 1.8264 â€” Train Acc: 42.38%
           â†’ Val Loss: 1.2425
Epoch 5/40 â€” Train Loss: 1.6160 â€” Train Acc: 47.80%
           â†’ Val Loss: 1.0796
Epoch 6/40 â€” Train Loss: 1.4811 â€” Train Acc: 51.57%
           â†’ Val Loss: 0.9376
Epoch 7/40 â€” Train Loss: 1.3682 â€” Train Acc: 54.71%
           â†’ Val Loss: 0.8762
Epoch 8/40 â€” Train Loss: 1.3094 â€” Train Acc: 56.34%
           â†’ Val Loss: 0.7986
Epoch 9/40 â€” Train Loss: 1.2370 â€” Train Acc: 58.22%
           â†’ Val Loss: 0.7427
Epoch 10/40 â€” Train Loss: 1.1947 â€” Train Acc: 60.03%
           â†’ Val Loss: 0.7027
Epoch 11/40 â€” Train Loss: 1.1511 â€” Train Acc: 61.09%
           â†’ Val Loss: 0.6771
Epoch 12/40 â€” Train Loss: 1.1189 â€” Train Acc: 61.97%
           â†’ Val Loss: 0.6427
Epoch 13/40 â€” Train Loss: 1.0800 â€” Train Acc: 63.08%
           â†’ Val Loss: 0.6124
Epoch 14/40 â€” Train Loss: 1.0533 â€” Train Acc: 63.84%
           â†’ Val Loss: 0.5904
Epoch 15/40 â€” Train Loss: 1.0176 â€” Train Acc: 65.05%
           â†’ Val Loss: 0.5872
Epoch 16/40 â€” Train Loss: 1.0040 â€” Train Acc: 65.57%
           â†’ Val Loss: 0.5390
Epoch 17/40 â€” Train Loss: 0.9717 â€” Train Acc: 66.71%
           â†’ Val Loss: 0.5604
Epoch 18/40 â€” Train Loss: 0.9680 â€” Train Acc: 66.45%
           â†’ Val Loss: 0.5233
Epoch 19/40 â€” Train Loss: 0.9453 â€” Train Acc: 67.41%
           â†’ Val Loss: 0.5223
Epoch 20/40 â€” Train Loss: 0.9131 â€” Train Acc: 68.25%
           â†’ Val Loss: 0.5007
Epoch 21/40 â€” Train Loss: 0.9145 â€” Train Acc: 68.27%
           â†’ Val Loss: 0.5136
Epoch 22/40 â€” Train Loss: 0.8943 â€” Train Acc: 68.59%
           â†’ Val Loss: 0.4705
Epoch 23/40 â€” Train Loss: 0.8799 â€” Train Acc: 69.53%
           â†’ Val Loss: 0.4602
Epoch 24/40 â€” Train Loss: 0.8702 â€” Train Acc: 69.79%
           â†’ Val Loss: 0.4562
Epoch 25/40 â€” Train Loss: 0.8490 â€” Train Acc: 69.93%
           â†’ Val Loss: 0.4492
Epoch 26/40 â€” Train Loss: 0.8427 â€” Train Acc: 70.56%
           â†’ Val Loss: 0.4207
Epoch 27/40 â€” Train Loss: 0.8277 â€” Train Acc: 71.12%
           â†’ Val Loss: 0.4247
Epoch 28/40 â€” Train Loss: 0.8241 â€” Train Acc: 71.31%
           â†’ Val Loss: 0.4154
Epoch 29/40 â€” Train Loss: 0.8036 â€” Train Acc: 71.67%
           â†’ Val Loss: 0.4091
Epoch 30/40 â€” Train Loss: 0.8000 â€” Train Acc: 72.04%
           â†’ Val Loss: 0.4073
Epoch 31/40 â€” Train Loss: 0.7917 â€” Train Acc: 72.21%
           â†’ Val Loss: 0.4028
Epoch 32/40 â€” Train Loss: 0.7782 â€” Train Acc: 72.52%
           â†’ Val Loss: 0.3950
Epoch 33/40 â€” Train Loss: 0.7659 â€” Train Acc: 72.91%
           â†’ Val Loss: 0.3815
Epoch 34/40 â€” Train Loss: 0.7666 â€” Train Acc: 73.04%
           â†’ Val Loss: 0.3609
Epoch 35/40 â€” Train Loss: 0.7573 â€” Train Acc: 73.36%
           â†’ Val Loss: 0.3742
Epoch 36/40 â€” Train Loss: 0.7370 â€” Train Acc: 74.00%
           â†’ Val Loss: 0.3666
Epoch 37/40 â€” Train Loss: 0.7282 â€” Train Acc: 74.20%
           â†’ Val Loss: 0.3541
Epoch 38/40 â€” Train Loss: 0.7324 â€” Train Acc: 74.38%
           â†’ Val Loss: 0.3434
Epoch 39/40 â€” Train Loss: 0.7243 â€” Train Acc: 74.37%
           â†’ Val Loss: 0.3431
Epoch 40/40 â€” Train Loss: 0.7145 â€” Train Acc: 74.85%
           â†’ Val Loss: 0.3418
âœ… Accuracy: 88.34%

ğŸ” Testing combination: {'lr': 0.0020142177594998875, 'batch_size': 8, 'dropout': 0.3926571035810738, 'conv_channels': [48, 96, 192], 'linear_size': 192, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.5805 â€” Train Acc: 3.05%
           â†’ Val Loss: 3.5803
Epoch 2/40 â€” Train Loss: 3.5788 â€” Train Acc: 3.03%
           â†’ Val Loss: 3.5799
Epoch 3/40 â€” Train Loss: 3.5788 â€” Train Acc: 3.04%
           â†’ Val Loss: 3.5806
Epoch 4/40 â€” Train Loss: 3.5788 â€” Train Acc: 3.12%
           â†’ Val Loss: 3.5804
Epoch 5/40 â€” Train Loss: 3.5790 â€” Train Acc: 3.08%
           â†’ Val Loss: 3.5791
Epoch 6/40 â€” Train Loss: 3.5790 â€” Train Acc: 2.94%
           â†’ Val Loss: 3.5801
â¹ï¸ Early stopping at epoch 6
âœ… Accuracy: 2.74%

ğŸ” Testing combination: {'lr': 0.00362106255043758, 'batch_size': 64, 'dropout': 0.23806360146183844, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.6023 â€” Train Acc: 2.97%
           â†’ Val Loss: 3.5798
Epoch 2/40 â€” Train Loss: 3.5786 â€” Train Acc: 2.89%
           â†’ Val Loss: 3.5795
Epoch 3/40 â€” Train Loss: 3.5784 â€” Train Acc: 3.14%
           â†’ Val Loss: 3.5795
Epoch 4/40 â€” Train Loss: 3.5784 â€” Train Acc: 2.92%
           â†’ Val Loss: 3.5799
Epoch 5/40 â€” Train Loss: 3.5784 â€” Train Acc: 2.85%
           â†’ Val Loss: 3.5795
Epoch 6/40 â€” Train Loss: 3.5783 â€” Train Acc: 3.07%
           â†’ Val Loss: 3.5793
â¹ï¸ Early stopping at epoch 6
âœ… Accuracy: 2.85%

ğŸ” Testing combination: {'lr': 0.00033997983244825016, 'batch_size': 64, 'dropout': 0.4719959104777049, 'conv_channels': [16, 32, 64], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.6485 â€” Train Acc: 22.72%
           â†’ Val Loss: 1.4274
Epoch 2/40 â€” Train Loss: 1.6595 â€” Train Acc: 46.01%
           â†’ Val Loss: 0.9883
Epoch 3/40 â€” Train Loss: 1.3804 â€” Train Acc: 54.17%
           â†’ Val Loss: 0.8104
Epoch 4/40 â€” Train Loss: 1.2214 â€” Train Acc: 58.36%
           â†’ Val Loss: 0.6857
Epoch 5/40 â€” Train Loss: 1.1212 â€” Train Acc: 61.30%
           â†’ Val Loss: 0.5941
Epoch 6/40 â€” Train Loss: 1.0396 â€” Train Acc: 64.25%
           â†’ Val Loss: 0.5227
Epoch 7/40 â€” Train Loss: 0.9745 â€” Train Acc: 65.94%
           â†’ Val Loss: 0.5038
Epoch 8/40 â€” Train Loss: 0.9230 â€” Train Acc: 67.48%
           â†’ Val Loss: 0.4796
Epoch 9/40 â€” Train Loss: 0.8750 â€” Train Acc: 69.20%
           â†’ Val Loss: 0.4220
Epoch 10/40 â€” Train Loss: 0.8513 â€” Train Acc: 70.04%
           â†’ Val Loss: 0.3997
Epoch 11/40 â€” Train Loss: 0.7993 â€” Train Acc: 71.55%
           â†’ Val Loss: 0.3893
Epoch 12/40 â€” Train Loss: 0.7758 â€” Train Acc: 72.26%
           â†’ Val Loss: 0.3605
Epoch 13/40 â€” Train Loss: 0.7487 â€” Train Acc: 73.46%
           â†’ Val Loss: 0.3359
Epoch 14/40 â€” Train Loss: 0.7127 â€” Train Acc: 74.56%
           â†’ Val Loss: 0.3227
Epoch 15/40 â€” Train Loss: 0.6981 â€” Train Acc: 74.91%
           â†’ Val Loss: 0.3299
Epoch 16/40 â€” Train Loss: 0.6746 â€” Train Acc: 75.89%
           â†’ Val Loss: 0.3273
Epoch 17/40 â€” Train Loss: 0.6639 â€” Train Acc: 76.38%
           â†’ Val Loss: 0.2810
Epoch 18/40 â€” Train Loss: 0.6343 â€” Train Acc: 77.46%
           â†’ Val Loss: 0.2669
Epoch 19/40 â€” Train Loss: 0.6235 â€” Train Acc: 77.53%
           â†’ Val Loss: 0.2484
Epoch 20/40 â€” Train Loss: 0.6035 â€” Train Acc: 78.44%
           â†’ Val Loss: 0.2514
Epoch 21/40 â€” Train Loss: 0.5917 â€” Train Acc: 78.47%
           â†’ Val Loss: 0.2484
Epoch 22/40 â€” Train Loss: 0.5876 â€” Train Acc: 78.90%
           â†’ Val Loss: 0.2406
Epoch 23/40 â€” Train Loss: 0.5633 â€” Train Acc: 79.65%
           â†’ Val Loss: 0.2444
Epoch 24/40 â€” Train Loss: 0.5549 â€” Train Acc: 80.13%
           â†’ Val Loss: 0.2128
Epoch 25/40 â€” Train Loss: 0.5471 â€” Train Acc: 80.57%
           â†’ Val Loss: 0.2058
Epoch 26/40 â€” Train Loss: 0.5301 â€” Train Acc: 80.67%
           â†’ Val Loss: 0.2152
Epoch 27/40 â€” Train Loss: 0.5227 â€” Train Acc: 81.24%
           â†’ Val Loss: 0.1978
Epoch 28/40 â€” Train Loss: 0.5042 â€” Train Acc: 81.99%
           â†’ Val Loss: 0.2038
Epoch 29/40 â€” Train Loss: 0.5056 â€” Train Acc: 82.00%
           â†’ Val Loss: 0.2033
Epoch 30/40 â€” Train Loss: 0.5018 â€” Train Acc: 82.09%
           â†’ Val Loss: 0.2078
Epoch 31/40 â€” Train Loss: 0.4905 â€” Train Acc: 82.72%
           â†’ Val Loss: 0.1967
Epoch 32/40 â€” Train Loss: 0.4653 â€” Train Acc: 83.31%
           â†’ Val Loss: 0.1762
Epoch 33/40 â€” Train Loss: 0.4686 â€” Train Acc: 83.15%
           â†’ Val Loss: 0.1871
Epoch 34/40 â€” Train Loss: 0.4661 â€” Train Acc: 83.32%
           â†’ Val Loss: 0.1718
Epoch 35/40 â€” Train Loss: 0.4526 â€” Train Acc: 83.85%
           â†’ Val Loss: 0.1743
Epoch 36/40 â€” Train Loss: 0.4536 â€” Train Acc: 83.79%
           â†’ Val Loss: 0.1712
Epoch 37/40 â€” Train Loss: 0.4431 â€” Train Acc: 84.16%
           â†’ Val Loss: 0.1684
â¹ï¸ Early stopping at epoch 37
âœ… Accuracy: 93.69%

ğŸ” Testing combination: {'lr': 0.00012199628685097639, 'batch_size': 128, 'dropout': 0.46826405136176685, 'conv_channels': [32, 64, 128], 'linear_size': 384, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.0050 â€” Train Acc: 15.12%
           â†’ Val Loss: 2.1267
Epoch 2/40 â€” Train Loss: 2.1477 â€” Train Acc: 35.30%
           â†’ Val Loss: 1.4177
Epoch 3/40 â€” Train Loss: 1.6851 â€” Train Acc: 46.93%
           â†’ Val Loss: 1.0264
Epoch 4/40 â€” Train Loss: 1.4479 â€” Train Acc: 53.01%
           â†’ Val Loss: 0.8713
Epoch 5/40 â€” Train Loss: 1.2964 â€” Train Acc: 57.28%
           â†’ Val Loss: 0.7291
Epoch 6/40 â€” Train Loss: 1.1945 â€” Train Acc: 60.31%
           â†’ Val Loss: 0.6810
Epoch 7/40 â€” Train Loss: 1.1016 â€” Train Acc: 63.12%
           â†’ Val Loss: 0.6246
Epoch 8/40 â€” Train Loss: 1.0435 â€” Train Acc: 64.64%
           â†’ Val Loss: 0.5843
Epoch 9/40 â€” Train Loss: 0.9845 â€” Train Acc: 66.55%
           â†’ Val Loss: 0.5421
Epoch 10/40 â€” Train Loss: 0.9429 â€” Train Acc: 67.94%
           â†’ Val Loss: 0.5063
Epoch 11/40 â€” Train Loss: 0.9020 â€” Train Acc: 68.98%
           â†’ Val Loss: 0.4735
Epoch 12/40 â€” Train Loss: 0.8707 â€” Train Acc: 70.03%
           â†’ Val Loss: 0.4247
Epoch 13/40 â€” Train Loss: 0.8428 â€” Train Acc: 70.53%
           â†’ Val Loss: 0.4163
Epoch 14/40 â€” Train Loss: 0.8128 â€” Train Acc: 72.11%
           â†’ Val Loss: 0.4018
Epoch 15/40 â€” Train Loss: 0.7857 â€” Train Acc: 72.79%
           â†’ Val Loss: 0.3856
Epoch 16/40 â€” Train Loss: 0.7714 â€” Train Acc: 73.42%
           â†’ Val Loss: 0.3667
Epoch 17/40 â€” Train Loss: 0.7546 â€” Train Acc: 73.68%
           â†’ Val Loss: 0.3661
Epoch 18/40 â€” Train Loss: 0.7263 â€” Train Acc: 74.92%
           â†’ Val Loss: 0.3434
Epoch 19/40 â€” Train Loss: 0.7159 â€” Train Acc: 75.20%
           â†’ Val Loss: 0.3318
Epoch 20/40 â€” Train Loss: 0.7024 â€” Train Acc: 75.45%
           â†’ Val Loss: 0.3272
Epoch 21/40 â€” Train Loss: 0.6830 â€” Train Acc: 75.97%
           â†’ Val Loss: 0.3196
Epoch 22/40 â€” Train Loss: 0.6720 â€” Train Acc: 76.69%
           â†’ Val Loss: 0.3031
Epoch 23/40 â€” Train Loss: 0.6514 â€” Train Acc: 77.24%
           â†’ Val Loss: 0.2931
Epoch 24/40 â€” Train Loss: 0.6416 â€” Train Acc: 77.38%
           â†’ Val Loss: 0.2727
Epoch 25/40 â€” Train Loss: 0.6333 â€” Train Acc: 77.60%
           â†’ Val Loss: 0.2784
Epoch 26/40 â€” Train Loss: 0.6136 â€” Train Acc: 78.35%
           â†’ Val Loss: 0.2709
Epoch 27/40 â€” Train Loss: 0.6129 â€” Train Acc: 78.56%
           â†’ Val Loss: 0.2600
Epoch 28/40 â€” Train Loss: 0.5931 â€” Train Acc: 79.31%
           â†’ Val Loss: 0.2488
Epoch 29/40 â€” Train Loss: 0.5846 â€” Train Acc: 79.22%
           â†’ Val Loss: 0.2434
Epoch 30/40 â€” Train Loss: 0.5756 â€” Train Acc: 79.84%
           â†’ Val Loss: 0.2416
Epoch 31/40 â€” Train Loss: 0.5667 â€” Train Acc: 80.11%
           â†’ Val Loss: 0.2432
Epoch 32/40 â€” Train Loss: 0.5662 â€” Train Acc: 80.03%
           â†’ Val Loss: 0.2417
Epoch 33/40 â€” Train Loss: 0.5505 â€” Train Acc: 80.49%
           â†’ Val Loss: 0.2569
â¹ï¸ Early stopping at epoch 33
âœ… Accuracy: 92.00%

ğŸ” Testing combination: {'lr': 0.005607625573948235, 'batch_size': 32, 'dropout': 0.21072444363358037, 'conv_channels': [48, 96, 192], 'linear_size': 384, 'activation': 'sigmoid', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.8662 â€” Train Acc: 2.71%
           â†’ Val Loss: 3.8283
Epoch 2/40 â€” Train Loss: 3.8684 â€” Train Acc: 3.01%
           â†’ Val Loss: 3.9147
Epoch 3/40 â€” Train Loss: 3.8728 â€” Train Acc: 2.80%
           â†’ Val Loss: 3.8931
Epoch 4/40 â€” Train Loss: 3.8734 â€” Train Acc: 2.86%
           â†’ Val Loss: 3.8962
Epoch 5/40 â€” Train Loss: 3.8740 â€” Train Acc: 2.85%
           â†’ Val Loss: 3.7092
Epoch 6/40 â€” Train Loss: 3.8582 â€” Train Acc: 2.90%
           â†’ Val Loss: 3.7168
Epoch 7/40 â€” Train Loss: 3.8683 â€” Train Acc: 2.94%
           â†’ Val Loss: 3.7960
Epoch 8/40 â€” Train Loss: 3.8755 â€” Train Acc: 2.78%
           â†’ Val Loss: 3.7377
Epoch 9/40 â€” Train Loss: 3.8598 â€” Train Acc: 2.91%
           â†’ Val Loss: 3.7924
Epoch 10/40 â€” Train Loss: 3.8718 â€” Train Acc: 2.71%
           â†’ Val Loss: 3.8136
â¹ï¸ Early stopping at epoch 10
âœ… Accuracy: 2.99%

ğŸ” Testing combination: {'lr': 0.0008976378638020268, 'batch_size': 32, 'dropout': 0.4109355077566278, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.1509 â€” Train Acc: 34.11%
           â†’ Val Loss: 0.9996
Epoch 2/40 â€” Train Loss: 1.1882 â€” Train Acc: 59.29%
           â†’ Val Loss: 0.6633
Epoch 3/40 â€” Train Loss: 0.9719 â€” Train Acc: 66.26%
           â†’ Val Loss: 0.5329
Epoch 4/40 â€” Train Loss: 0.8403 â€” Train Acc: 70.83%
           â†’ Val Loss: 0.4147
Epoch 5/40 â€” Train Loss: 0.7572 â€” Train Acc: 73.62%
           â†’ Val Loss: 0.3551
Epoch 6/40 â€” Train Loss: 0.7130 â€” Train Acc: 74.94%
           â†’ Val Loss: 0.3622
Epoch 7/40 â€” Train Loss: 0.6631 â€” Train Acc: 76.67%
           â†’ Val Loss: 0.2995
Epoch 8/40 â€” Train Loss: 0.6166 â€” Train Acc: 78.41%
           â†’ Val Loss: 0.2848
Epoch 9/40 â€” Train Loss: 0.5933 â€” Train Acc: 79.28%
           â†’ Val Loss: 0.2752
Epoch 10/40 â€” Train Loss: 0.5635 â€” Train Acc: 80.54%
           â†’ Val Loss: 0.2599
Epoch 11/40 â€” Train Loss: 0.5429 â€” Train Acc: 80.85%
           â†’ Val Loss: 0.2298
Epoch 12/40 â€” Train Loss: 0.5290 â€” Train Acc: 81.42%
           â†’ Val Loss: 0.2375
Epoch 13/40 â€” Train Loss: 0.5164 â€” Train Acc: 81.93%
           â†’ Val Loss: 0.2073
Epoch 14/40 â€” Train Loss: 0.4871 â€” Train Acc: 82.64%
           â†’ Val Loss: 0.2192
Epoch 15/40 â€” Train Loss: 0.4886 â€” Train Acc: 82.85%
           â†’ Val Loss: 0.2090
Epoch 16/40 â€” Train Loss: 0.4699 â€” Train Acc: 83.50%
           â†’ Val Loss: 0.2045
Epoch 17/40 â€” Train Loss: 0.4489 â€” Train Acc: 84.23%
           â†’ Val Loss: 0.1975
Epoch 18/40 â€” Train Loss: 0.4397 â€” Train Acc: 84.55%
           â†’ Val Loss: 0.1887
Epoch 19/40 â€” Train Loss: 0.4319 â€” Train Acc: 84.89%
           â†’ Val Loss: 0.1765
Epoch 20/40 â€” Train Loss: 0.4252 â€” Train Acc: 84.85%
           â†’ Val Loss: 0.1656
Epoch 21/40 â€” Train Loss: 0.4207 â€” Train Acc: 85.55%
           â†’ Val Loss: 0.1751
Epoch 22/40 â€” Train Loss: 0.4161 â€” Train Acc: 85.42%
           â†’ Val Loss: 0.1636
Epoch 23/40 â€” Train Loss: 0.4010 â€” Train Acc: 85.71%
           â†’ Val Loss: 0.1711
Epoch 24/40 â€” Train Loss: 0.4046 â€” Train Acc: 85.83%
           â†’ Val Loss: 0.1769
Epoch 25/40 â€” Train Loss: 0.3946 â€” Train Acc: 86.31%
           â†’ Val Loss: 0.1580
â¹ï¸ Early stopping at epoch 25
âœ… Accuracy: 93.96%

ğŸ” Testing combination: {'lr': 0.005731620426505748, 'batch_size': 32, 'dropout': 0.3531326078142447, 'conv_channels': [48, 96, 192], 'linear_size': 192, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.6234 â€” Train Acc: 3.02%
           â†’ Val Loss: 3.5798
Epoch 2/40 â€” Train Loss: 3.5793 â€” Train Acc: 2.96%
           â†’ Val Loss: 3.5802
Epoch 3/40 â€” Train Loss: 3.5793 â€” Train Acc: 2.95%
           â†’ Val Loss: 3.5815
Epoch 4/40 â€” Train Loss: 3.5792 â€” Train Acc: 3.17%
           â†’ Val Loss: 3.5806
Epoch 5/40 â€” Train Loss: 3.5793 â€” Train Acc: 3.10%
           â†’ Val Loss: 3.5798
Epoch 6/40 â€” Train Loss: 3.5794 â€” Train Acc: 3.01%
           â†’ Val Loss: 3.5798
â¹ï¸ Early stopping at epoch 6
âœ… Accuracy: 2.82%

ğŸ” Testing combination: {'lr': 0.0001587022628498408, 'batch_size': 64, 'dropout': 0.2988524828886524, 'conv_channels': [48, 96, 192], 'linear_size': 128, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.7810 â€” Train Acc: 21.44%
           â†’ Val Loss: 1.6530
Epoch 2/40 â€” Train Loss: 1.8271 â€” Train Acc: 42.56%
           â†’ Val Loss: 1.1025
Epoch 3/40 â€” Train Loss: 1.4974 â€” Train Acc: 51.12%
           â†’ Val Loss: 0.8983
Epoch 4/40 â€” Train Loss: 1.3323 â€” Train Acc: 55.71%
           â†’ Val Loss: 0.7773
Epoch 5/40 â€” Train Loss: 1.1994 â€” Train Acc: 59.52%
           â†’ Val Loss: 0.7084
Epoch 6/40 â€” Train Loss: 1.1147 â€” Train Acc: 62.16%
           â†’ Val Loss: 0.6504
Epoch 7/40 â€” Train Loss: 1.0345 â€” Train Acc: 64.50%
           â†’ Val Loss: 0.6115
Epoch 8/40 â€” Train Loss: 0.9936 â€” Train Acc: 65.82%
           â†’ Val Loss: 0.5119
Epoch 9/40 â€” Train Loss: 0.9453 â€” Train Acc: 67.37%
           â†’ Val Loss: 0.5176
Epoch 10/40 â€” Train Loss: 0.8998 â€” Train Acc: 68.81%
           â†’ Val Loss: 0.4767
Epoch 11/40 â€” Train Loss: 0.8636 â€” Train Acc: 69.74%
           â†’ Val Loss: 0.4396
Epoch 12/40 â€” Train Loss: 0.8265 â€” Train Acc: 71.04%
           â†’ Val Loss: 0.4354
Epoch 13/40 â€” Train Loss: 0.8043 â€” Train Acc: 71.65%
           â†’ Val Loss: 0.4090
Epoch 14/40 â€” Train Loss: 0.7621 â€” Train Acc: 73.10%
           â†’ Val Loss: 0.3829
Epoch 15/40 â€” Train Loss: 0.7395 â€” Train Acc: 73.92%
           â†’ Val Loss: 0.3798
Epoch 16/40 â€” Train Loss: 0.7271 â€” Train Acc: 74.63%
           â†’ Val Loss: 0.3611
Epoch 17/40 â€” Train Loss: 0.6993 â€” Train Acc: 75.31%
           â†’ Val Loss: 0.3231
Epoch 18/40 â€” Train Loss: 0.6741 â€” Train Acc: 76.45%
           â†’ Val Loss: 0.3346
Epoch 19/40 â€” Train Loss: 0.6636 â€” Train Acc: 76.25%
           â†’ Val Loss: 0.3303
Epoch 20/40 â€” Train Loss: 0.6544 â€” Train Acc: 76.71%
           â†’ Val Loss: 0.3133
Epoch 21/40 â€” Train Loss: 0.6380 â€” Train Acc: 77.35%
           â†’ Val Loss: 0.3100
Epoch 22/40 â€” Train Loss: 0.6173 â€” Train Acc: 78.19%
           â†’ Val Loss: 0.2967
Epoch 23/40 â€” Train Loss: 0.6050 â€” Train Acc: 78.28%
           â†’ Val Loss: 0.2745
Epoch 24/40 â€” Train Loss: 0.5927 â€” Train Acc: 79.45%
           â†’ Val Loss: 0.2673
Epoch 25/40 â€” Train Loss: 0.5755 â€” Train Acc: 79.59%
           â†’ Val Loss: 0.2552
Epoch 26/40 â€” Train Loss: 0.5615 â€” Train Acc: 80.16%
           â†’ Val Loss: 0.2640
Epoch 27/40 â€” Train Loss: 0.5589 â€” Train Acc: 80.26%
           â†’ Val Loss: 0.2548
Epoch 28/40 â€” Train Loss: 0.5436 â€” Train Acc: 80.72%
           â†’ Val Loss: 0.2575
Epoch 29/40 â€” Train Loss: 0.5319 â€” Train Acc: 81.25%
           â†’ Val Loss: 0.2500
Epoch 30/40 â€” Train Loss: 0.5284 â€” Train Acc: 81.16%
           â†’ Val Loss: 0.2334
Epoch 31/40 â€” Train Loss: 0.5212 â€” Train Acc: 81.79%
           â†’ Val Loss: 0.2259
Epoch 32/40 â€” Train Loss: 0.5065 â€” Train Acc: 81.99%
           â†’ Val Loss: 0.2225
Epoch 33/40 â€” Train Loss: 0.4948 â€” Train Acc: 82.76%
           â†’ Val Loss: 0.2292
Epoch 34/40 â€” Train Loss: 0.4948 â€” Train Acc: 82.52%
           â†’ Val Loss: 0.2092
Epoch 35/40 â€” Train Loss: 0.4892 â€” Train Acc: 82.58%
           â†’ Val Loss: 0.2064
Epoch 36/40 â€” Train Loss: 0.4705 â€” Train Acc: 83.18%
           â†’ Val Loss: 0.2000
Epoch 37/40 â€” Train Loss: 0.4628 â€” Train Acc: 83.48%
           â†’ Val Loss: 0.2095
Epoch 38/40 â€” Train Loss: 0.4546 â€” Train Acc: 83.90%
           â†’ Val Loss: 0.2137
Epoch 39/40 â€” Train Loss: 0.4528 â€” Train Acc: 83.71%
           â†’ Val Loss: 0.1884
Epoch 40/40 â€” Train Loss: 0.4482 â€” Train Acc: 84.31%
           â†’ Val Loss: 0.1942
âœ… Accuracy: 93.19%

ğŸ” Testing combination: {'lr': 0.00010693644868988849, 'batch_size': 32, 'dropout': 0.3946585293722291, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 2.3373 â€” Train Acc: 31.80%
           â†’ Val Loss: 1.1174
Epoch 2/40 â€” Train Loss: 1.3491 â€” Train Acc: 56.28%
           â†’ Val Loss: 0.6701
Epoch 3/40 â€” Train Loss: 1.0489 â€” Train Acc: 65.25%
           â†’ Val Loss: 0.5198
Epoch 4/40 â€” Train Loss: 0.8652 â€” Train Acc: 70.85%
           â†’ Val Loss: 0.4330
Epoch 5/40 â€” Train Loss: 0.7490 â€” Train Acc: 74.24%
           â†’ Val Loss: 0.3659
Epoch 6/40 â€” Train Loss: 0.6572 â€” Train Acc: 77.27%
           â†’ Val Loss: 0.3158
Epoch 7/40 â€” Train Loss: 0.5978 â€” Train Acc: 79.18%
           â†’ Val Loss: 0.2786
Epoch 8/40 â€” Train Loss: 0.5602 â€” Train Acc: 80.47%
           â†’ Val Loss: 0.2496
Epoch 9/40 â€” Train Loss: 0.5207 â€” Train Acc: 81.93%
           â†’ Val Loss: 0.2371
Epoch 10/40 â€” Train Loss: 0.4788 â€” Train Acc: 83.30%
           â†’ Val Loss: 0.2202
Epoch 11/40 â€” Train Loss: 0.4505 â€” Train Acc: 84.60%
           â†’ Val Loss: 0.2044
Epoch 12/40 â€” Train Loss: 0.4246 â€” Train Acc: 85.31%
           â†’ Val Loss: 0.1794
Epoch 13/40 â€” Train Loss: 0.3964 â€” Train Acc: 86.11%
           â†’ Val Loss: 0.1853
Epoch 14/40 â€” Train Loss: 0.3901 â€” Train Acc: 86.40%
           â†’ Val Loss: 0.1684
Epoch 15/40 â€” Train Loss: 0.3706 â€” Train Acc: 87.25%
           â†’ Val Loss: 0.1701
Epoch 16/40 â€” Train Loss: 0.3463 â€” Train Acc: 87.97%
           â†’ Val Loss: 0.1541
Epoch 17/40 â€” Train Loss: 0.3439 â€” Train Acc: 88.08%
           â†’ Val Loss: 0.1431
Epoch 18/40 â€” Train Loss: 0.3201 â€” Train Acc: 88.81%
           â†’ Val Loss: 0.1495
Epoch 19/40 â€” Train Loss: 0.3128 â€” Train Acc: 89.11%
           â†’ Val Loss: 0.1431
Epoch 20/40 â€” Train Loss: 0.2959 â€” Train Acc: 89.83%
           â†’ Val Loss: 0.1207
Epoch 21/40 â€” Train Loss: 0.2958 â€” Train Acc: 89.80%
           â†’ Val Loss: 0.1193
Epoch 22/40 â€” Train Loss: 0.2800 â€” Train Acc: 90.34%
           â†’ Val Loss: 0.1122
Epoch 23/40 â€” Train Loss: 0.2715 â€” Train Acc: 90.91%
           â†’ Val Loss: 0.1219
Epoch 24/40 â€” Train Loss: 0.2630 â€” Train Acc: 90.95%
           â†’ Val Loss: 0.1021
Epoch 25/40 â€” Train Loss: 0.2578 â€” Train Acc: 91.17%
           â†’ Val Loss: 0.1106
Epoch 26/40 â€” Train Loss: 0.2530 â€” Train Acc: 91.35%
           â†’ Val Loss: 0.1212
Epoch 27/40 â€” Train Loss: 0.2399 â€” Train Acc: 91.83%
           â†’ Val Loss: 0.0905
Epoch 28/40 â€” Train Loss: 0.2356 â€” Train Acc: 91.97%
           â†’ Val Loss: 0.1000
Epoch 29/40 â€” Train Loss: 0.2277 â€” Train Acc: 92.34%
           â†’ Val Loss: 0.0929
Epoch 30/40 â€” Train Loss: 0.2166 â€” Train Acc: 92.50%
           â†’ Val Loss: 0.0941
Epoch 31/40 â€” Train Loss: 0.2154 â€” Train Acc: 92.58%
           â†’ Val Loss: 0.0849
Epoch 32/40 â€” Train Loss: 0.2156 â€” Train Acc: 92.83%
           â†’ Val Loss: 0.0938
â¹ï¸ Early stopping at epoch 32
âœ… Accuracy: 96.93%

ğŸ” Testing combination: {'lr': 0.0004883933424704293, 'batch_size': 32, 'dropout': 0.2152662437829637, 'conv_channels': [48, 96, 192], 'linear_size': 128, 'activation': 'sigmoid', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 â€” Train Loss: 3.6060 â€” Train Acc: 3.16%
           â†’ Val Loss: 3.5882
Epoch 2/40 â€” Train Loss: 3.6022 â€” Train Acc: 2.96%
           â†’ Val Loss: 3.5851
Epoch 3/40 â€” Train Loss: 3.5991 â€” Train Acc: 3.05%
           â†’ Val Loss: 3.5844
=======
ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.07%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 86.62%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 83.47%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.49%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 81.25%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 82.89%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.41%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 84.41%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 86.60%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.71%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 85.68%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
âœ… Accuracy: 85.13%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
âœ… Accuracy: 85.27%

ğŸ” Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
âœ… Accuracy: 86.40%
>>>>>>> f547d8b26c7d13467fcb7bc5d329bc0f53f3e7f3
