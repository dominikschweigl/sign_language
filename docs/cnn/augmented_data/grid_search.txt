<<<<<<< HEAD
not augmented data, but with balancing:
=======
>>>>>>> f547d8b26c7d13467fcb7bc5d329bc0f53f3e7f3

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 84.33%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 88.04%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 86.13%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.57%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.65%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 84.05%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.74%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.35%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.24%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 81.56%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.93%

🔍 Testing combination: {'epochs': 1, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 86.01%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 84.91%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 83.91%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.32%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.24%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.21%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 86.49%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 84.19%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 86.07%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.24%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.29%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.52%

🔍 Testing combination: {'epochs': 1, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 84.66%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.77%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 83.36%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 83.74%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.07%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 83.99%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 84.27%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.66%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 83.91%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.02%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 82.86%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 86.79%

🔍 Testing combination: {'epochs': 3, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 84.05%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 84.08%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 86.71%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 86.40%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 81.00%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.13%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.96%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 82.75%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.79%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.24%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.11%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 86.60%

🔍 Testing combination: {'epochs': 3, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 87.43%

<<<<<<< HEAD

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 86.24%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.38%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 82.39%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 84.60%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.35%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 83.16%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 84.19%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 83.44%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.46%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.97%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.43%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 82.25%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.16%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 82.77%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 86.60%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 81.64%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.99%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 86.79%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 84.27%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.99%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.63%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.25%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.57%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 86.07%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.27%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 83.83%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 82.61%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.19%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 82.44%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 83.38%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 82.41%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.93%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 83.80%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.63%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.96%

🔍 Testing combination: {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.16%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.85%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.13%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.27%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 84.74%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.91%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 84.46%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 82.83%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.52%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 83.30%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 83.99%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.05%

🔍 Testing combination: {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 84.41%

1. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 86.79%
2. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 86.60%
3. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 86.24%
4. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 86.07%
5. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 85.93%
6. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 85.63%
7. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 85.52%
8. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 85.46%
9. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 85.43%
10. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 85.35%
11. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 85.27%
12. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 85.27%
13. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 85.16%
14. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 85.13%
15. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.99%
16. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 84.99%
17. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.96%
18. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.91%
19. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 84.74%
20. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 84.60%
21. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.57%
22. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 84.46%
23. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 84.41%
24. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 84.38%
25. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 84.27%
26. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 84.19%
27. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 84.05%
28. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.99%
29. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.97%
30. {'epochs': 10, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 83.85%
31. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 83.83%
32. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 83.80%
33. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.63%
34. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 83.44%
35. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 83.38%
36. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 83.30%
37. {'epochs': 5, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.25%
38. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 83.19%
39. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 83.16%
40. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 83.16%
41. {'epochs': 10, 'lr': 0.0005, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 82.83%
42. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]} => Accuracy: 82.77%
43. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 82.61%
44. {'epochs': 10, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]} => Accuracy: 82.44%
45. {'epochs': 10, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]} => Accuracy: 82.41%
46. {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]} => Accuracy: 82.39%
47. {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]} => Accuracy: 82.25%
48. {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]} => Accuracy: 81.64%


with augmented data:

🔍 Testing combination: {'lr': 0.008252553143535197, 'batch_size': 64, 'dropout': 0.26517306957493525, 'conv_channels': [16, 32, 64], 'linear_size': 128, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 2.74%

🔍 Testing combination: {'lr': 0.005491080462828726, 'batch_size': 64, 'dropout': 0.3717566897162151, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.99%

🔍 Testing combination: {'lr': 0.006785057154116505, 'batch_size': 16, 'dropout': 0.41974795194886466, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 2.94%

🔍 Testing combination: {'lr': 0.0018357335559105, 'batch_size': 16, 'dropout': 0.29581787387970687, 'conv_channels': [48, 96, 192], 'linear_size': 192, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.96%

🔍 Testing combination: {'lr': 0.009214597882685915, 'batch_size': 128, 'dropout': 0.42825058491264933, 'conv_channels': [16, 32, 64], 'linear_size': 256, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.85%

🔍 Testing combination: {'lr': 0.008472404786846863, 'batch_size': 64, 'dropout': 0.20687608884323744, 'conv_channels': [48, 96, 192], 'linear_size': 192, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 2.55%

🔍 Testing combination: {'lr': 0.0061560677355620725, 'batch_size': 16, 'dropout': 0.4566638535683986, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 3.41%

🔍 Testing combination: {'lr': 0.004231558445316906, 'batch_size': 128, 'dropout': 0.299500196768424, 'conv_channels': [16, 32, 64], 'linear_size': 128, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 2.82%

🔍 Testing combination: {'lr': 0.008781598617037548, 'batch_size': 128, 'dropout': 0.4706317380904241, 'conv_channels': [32, 64, 128], 'linear_size': 128, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.96%

🔍 Testing combination: {'lr': 0.0042625203246274375, 'batch_size': 128, 'dropout': 0.3193044771278613, 'conv_channels': [16, 32, 64], 'linear_size': 256, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 84.99%

🔍 Testing combination: {'lr': 0.001458620894753208, 'batch_size': 64, 'dropout': 0.3483392326394138, 'conv_channels': [48, 96, 192], 'linear_size': 384, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 2.19%

🔍 Testing combination: {'lr': 0.008842351712883797, 'batch_size': 128, 'dropout': 0.2956595185840582, 'conv_channels': [16, 32, 64], 'linear_size': 128, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 3.05%

🔍 Testing combination: {'lr': 0.0013443736297744924, 'batch_size': 8, 'dropout': 0.4998578352983471, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.85%

🔍 Testing combination: {'lr': 0.004063612008344013, 'batch_size': 64, 'dropout': 0.41778909849679546, 'conv_channels': [32, 64, 128], 'linear_size': 384, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 91.30%

🔍 Testing combination: {'lr': 0.0022651724318132347, 'batch_size': 8, 'dropout': 0.2992859150762729, 'conv_channels': [32, 64, 128], 'linear_size': 128, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.82%

🔍 Testing combination: {'lr': 0.0066553734398453615, 'batch_size': 16, 'dropout': 0.33093802584451626, 'conv_channels': [32, 64, 128], 'linear_size': 192, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 2.38%

🔍 Testing combination: {'lr': 0.0028308651296598203, 'batch_size': 8, 'dropout': 0.29610900518394584, 'conv_channels': [32, 64, 128], 'linear_size': 384, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.94%

🔍 Testing combination: {'lr': 0.004740373521024221, 'batch_size': 32, 'dropout': 0.31214006350331736, 'conv_channels': [48, 96, 192], 'linear_size': 384, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.94%

🔍 Testing combination: {'lr': 0.00786751593961708, 'batch_size': 8, 'dropout': 0.3924853698484403, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'sigmoid', 'epochs': 40}
✅ Accuracy: 2.58%

🔍 Testing combination: {'lr': 0.007781540856414062, 'batch_size': 32, 'dropout': 0.25343884223093527, 'conv_channels': [48, 96, 192], 'linear_size': 384, 'activation': 'relu', 'epochs': 40}
✅ Accuracy: 2.74%

🔍 Testing combination: {'lr': 0.00042078338960087374, 'batch_size': 32, 'dropout': 0.3204658731577415, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'epochs': 40}
Epoch 1/40 — Train Loss: 2.2188 — Train Acc: 32.81%
Epoch 2/40 — Train Loss: 1.2821 — Train Acc: 56.51%
Epoch 3/40 — Train Loss: 1.0215 — Train Acc: 64.74%
Epoch 4/40 — Train Loss: 0.8658 — Train Acc: 69.55%
Epoch 5/40 — Train Loss: 0.7736 — Train Acc: 72.80%
Epoch 6/40 — Train Loss: 0.7094 — Train Acc: 74.91%
Epoch 7/40 — Train Loss: 0.6496 — Train Acc: 76.85%
Epoch 8/40 — Train Loss: 0.6140 — Train Acc: 78.32%
Epoch 9/40 — Train Loss: 0.5701 — Train Acc: 79.38%
Epoch 10/40 — Train Loss: 0.5416 — Train Acc: 80.51%
Epoch 11/40 — Train Loss: 0.5159 — Train Acc: 81.54%
Epoch 12/40 — Train Loss: 0.4934 — Train Acc: 82.49%
Epoch 13/40 — Train Loss: 0.4624 — Train Acc: 83.48%
Epoch 14/40 — Train Loss: 0.4537 — Train Acc: 83.79%
Epoch 15/40 — Train Loss: 0.4369 — Train Acc: 84.86%
Epoch 16/40 — Train Loss: 0.4194 — Train Acc: 84.90%
Epoch 17/40 — Train Loss: 0.4017 — Train Acc: 85.84%
Epoch 18/40 — Train Loss: 0.3890 — Train Acc: 86.17%
Epoch 19/40 — Train Loss: 0.3794 — Train Acc: 86.66%
Epoch 20/40 — Train Loss: 0.3679 — Train Acc: 86.84%
Epoch 21/40 — Train Loss: 0.3557 — Train Acc: 87.45%
Epoch 22/40 — Train Loss: 0.3629 — Train Acc: 87.11%
Epoch 23/40 — Train Loss: 0.3452 — Train Acc: 87.95%
Epoch 24/40 — Train Loss: 0.3366 — Train Acc: 88.14%
Epoch 25/40 — Train Loss: 0.3299 — Train Acc: 88.52%
Epoch 26/40 — Train Loss: 0.3235 — Train Acc: 88.49%
Epoch 27/40 — Train Loss: 0.3056 — Train Acc: 89.35%
Epoch 28/40 — Train Loss: 0.3043 — Train Acc: 89.25%
Epoch 29/40 — Train Loss: 0.3032 — Train Acc: 89.19%
Epoch 30/40 — Train Loss: 0.2992 — Train Acc: 89.49%
Epoch 31/40 — Train Loss: 0.2875 — Train Acc: 89.96%
Epoch 32/40 — Train Loss: 0.2842 — Train Acc: 90.01%
Epoch 33/40 — Train Loss: 0.2756 — Train Acc: 90.27%
Epoch 34/40 — Train Loss: 0.2683 — Train Acc: 90.59%
Epoch 35/40 — Train Loss: 0.2746 — Train Acc: 90.46%
Epoch 36/40 — Train Loss: 0.2656 — Train Acc: 90.87%
Epoch 37/40 — Train Loss: 0.2688 — Train Acc: 90.69%
Epoch 38/40 — Train Loss: 0.2644 — Train Acc: 90.57%
Epoch 39/40 — Train Loss: 0.2507 — Train Acc: 91.26%
Epoch 40/40 — Train Loss: 0.2433 — Train Acc: 91.38%
✅ Accuracy: 96.62%

🔍 Testing combination: {'lr': 0.00015577215767958094, 'batch_size': 32, 'dropout': 0.30614472743709187, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'sigmoid', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.5960 — Train Acc: 2.83%
           → Val Loss: 3.5795
Epoch 2/40 — Train Loss: 3.5817 — Train Acc: 2.95%
           → Val Loss: 3.5800
Epoch 3/40 — Train Loss: 3.5799 — Train Acc: 3.19%
           → Val Loss: 3.5794
Epoch 4/40 — Train Loss: 3.5782 — Train Acc: 3.30%
           → Val Loss: 3.5729
Epoch 5/40 — Train Loss: 3.4108 — Train Acc: 7.69%
           → Val Loss: 3.1415
Epoch 6/40 — Train Loss: 3.0373 — Train Acc: 15.76%
           → Val Loss: 2.8732
Epoch 7/40 — Train Loss: 2.8584 — Train Acc: 19.01%
           → Val Loss: 2.7144
Epoch 8/40 — Train Loss: 2.7421 — Train Acc: 20.93%
           → Val Loss: 2.5749
Epoch 9/40 — Train Loss: 2.6601 — Train Acc: 22.98%
           → Val Loss: 2.4934
Epoch 10/40 — Train Loss: 2.5879 — Train Acc: 24.48%
           → Val Loss: 2.3980
Epoch 11/40 — Train Loss: 2.5170 — Train Acc: 26.20%
           → Val Loss: 2.3231
Epoch 12/40 — Train Loss: 2.4655 — Train Acc: 27.69%
           → Val Loss: 2.2506
Epoch 13/40 — Train Loss: 2.4127 — Train Acc: 27.96%
           → Val Loss: 2.1797
Epoch 14/40 — Train Loss: 2.3731 — Train Acc: 28.50%
           → Val Loss: 2.1628
Epoch 15/40 — Train Loss: 2.3282 — Train Acc: 30.37%
           → Val Loss: 2.0843
Epoch 16/40 — Train Loss: 2.2997 — Train Acc: 30.70%
           → Val Loss: 2.0548
Epoch 17/40 — Train Loss: 2.2678 — Train Acc: 31.48%
           → Val Loss: 2.0358
Epoch 18/40 — Train Loss: 2.2404 — Train Acc: 32.31%
           → Val Loss: 1.9847


🔍 Testing combination: {'lr': 0.000463246648991257, 'batch_size': 32, 'dropout': 0.45530686154029965, 'conv_channels': [32, 64, 128], 'linear_size': 256, 'activation': 'sigmoid', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.6352 — Train Acc: 2.96%
           → Val Loss: 3.5909
Epoch 2/40 — Train Loss: 3.6211 — Train Acc: 2.84%
           → Val Loss: 3.5885
Epoch 3/40 — Train Loss: 3.6107 — Train Acc: 3.04%
           → Val Loss: 3.5934
Epoch 4/40 — Train Loss: 3.6053 — Train Acc: 3.10%
           → Val Loss: 3.5817
Epoch 5/40 — Train Loss: 3.6023 — Train Acc: 2.86%
           → Val Loss: 3.5878
Epoch 6/40 — Train Loss: 3.6013 — Train Acc: 2.93%
           → Val Loss: 3.5880
⏹️ Early stopping at epoch 6
✅ Accuracy: 2.96%

🔍 Testing combination: {'lr': 0.0002400641350354702, 'batch_size': 64, 'dropout': 0.36043523654320486, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.1815 — Train Acc: 35.34%
           → Val Loss: 1.0072
Epoch 2/40 — Train Loss: 1.1915 — Train Acc: 60.82%
           → Val Loss: 0.6146
Epoch 3/40 — Train Loss: 0.8900 — Train Acc: 69.99%
           → Val Loss: 0.4220
Epoch 4/40 — Train Loss: 0.7344 — Train Acc: 74.71%
           → Val Loss: 0.3502
Epoch 5/40 — Train Loss: 0.6451 — Train Acc: 77.37%
           → Val Loss: 0.3133
Epoch 6/40 — Train Loss: 0.5709 — Train Acc: 79.74%
           → Val Loss: 0.2716
Epoch 7/40 — Train Loss: 0.5248 — Train Acc: 81.66%
           → Val Loss: 0.2451
Epoch 8/40 — Train Loss: 0.4900 — Train Acc: 82.54%
           → Val Loss: 0.2349
Epoch 9/40 — Train Loss: 0.4519 — Train Acc: 83.88%
           → Val Loss: 0.2044
Epoch 10/40 — Train Loss: 0.4170 — Train Acc: 85.40%
           → Val Loss: 0.1934
Epoch 11/40 — Train Loss: 0.3957 — Train Acc: 86.12%
           → Val Loss: 0.1706
Epoch 12/40 — Train Loss: 0.3821 — Train Acc: 86.40%
           → Val Loss: 0.1679
Epoch 13/40 — Train Loss: 0.3547 — Train Acc: 87.23%
           → Val Loss: 0.1586
Epoch 14/40 — Train Loss: 0.3526 — Train Acc: 87.59%
           → Val Loss: 0.1494
Epoch 15/40 — Train Loss: 0.3273 — Train Acc: 88.58%
           → Val Loss: 0.1585
Epoch 16/40 — Train Loss: 0.3134 — Train Acc: 88.67%
           → Val Loss: 0.1465
Epoch 17/40 — Train Loss: 0.3016 — Train Acc: 89.45%
           → Val Loss: 0.1499
Epoch 18/40 — Train Loss: 0.2944 — Train Acc: 89.74%
           → Val Loss: 0.1312
Epoch 19/40 — Train Loss: 0.2878 — Train Acc: 89.86%
           → Val Loss: 0.1284
Epoch 20/40 — Train Loss: 0.2617 — Train Acc: 90.94%
           → Val Loss: 0.1137
Epoch 21/40 — Train Loss: 0.2593 — Train Acc: 90.92%
           → Val Loss: 0.1186
Epoch 22/40 — Train Loss: 0.2549 — Train Acc: 90.97%
           → Val Loss: 0.0995
Epoch 23/40 — Train Loss: 0.2518 — Train Acc: 91.27%
           → Val Loss: 0.1001
Epoch 24/40 — Train Loss: 0.2435 — Train Acc: 91.56%
           → Val Loss: 0.1036
Epoch 25/40 — Train Loss: 0.2382 — Train Acc: 91.57%
           → Val Loss: 0.1034
Epoch 26/40 — Train Loss: 0.2263 — Train Acc: 92.25%
           → Val Loss: 0.0986
Epoch 27/40 — Train Loss: 0.2268 — Train Acc: 92.28%
           → Val Loss: 0.0959
⏹️ Early stopping at epoch 27
✅ Accuracy: 96.59%

🔍 Testing combination: {'lr': 0.0013453987202164453, 'batch_size': 8, 'dropout': 0.22573386745693555, 'conv_channels': [32, 64, 128], 'linear_size': 128, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.2366 — Train Acc: 30.34%
           → Val Loss: 1.3291
Epoch 2/40 — Train Loss: 1.5121 — Train Acc: 48.82%
           → Val Loss: 1.0453
Epoch 3/40 — Train Loss: 1.3067 — Train Acc: 55.32%
           → Val Loss: 0.8092
Epoch 4/40 — Train Loss: 1.1980 — Train Acc: 58.65%
           → Val Loss: 0.7655
Epoch 5/40 — Train Loss: 1.1284 — Train Acc: 61.02%
           → Val Loss: 0.6379
Epoch 6/40 — Train Loss: 1.0611 — Train Acc: 63.16%
           → Val Loss: 0.6720
Epoch 7/40 — Train Loss: 1.0165 — Train Acc: 64.58%
           → Val Loss: 0.6161
Epoch 8/40 — Train Loss: 0.9779 — Train Acc: 65.31%
           → Val Loss: 0.6178
Epoch 9/40 — Train Loss: 0.9435 — Train Acc: 66.83%
           → Val Loss: 0.5276
Epoch 10/40 — Train Loss: 0.9327 — Train Acc: 67.32%
           → Val Loss: 0.5140
Epoch 11/40 — Train Loss: 0.9115 — Train Acc: 68.35%
           → Val Loss: 0.5268
Epoch 12/40 — Train Loss: 0.8814 — Train Acc: 68.96%
           → Val Loss: 0.5197
Epoch 13/40 — Train Loss: 0.8758 — Train Acc: 69.29%
           → Val Loss: 0.4843
Epoch 14/40 — Train Loss: 0.8515 — Train Acc: 70.16%
           → Val Loss: 0.4684
Epoch 15/40 — Train Loss: 0.8371 — Train Acc: 70.66%
           → Val Loss: 0.4853
Epoch 16/40 — Train Loss: 0.8268 — Train Acc: 71.03%
           → Val Loss: 0.4584
Epoch 17/40 — Train Loss: 0.8120 — Train Acc: 71.68%
           → Val Loss: 0.4545
Epoch 18/40 — Train Loss: 0.8034 — Train Acc: 71.97%
           → Val Loss: 0.4458
Epoch 19/40 — Train Loss: 0.7892 — Train Acc: 72.51%
           → Val Loss: 0.4682
Epoch 20/40 — Train Loss: 0.7856 — Train Acc: 72.77%
           → Val Loss: 0.4396
Epoch 21/40 — Train Loss: 0.7768 — Train Acc: 73.00%
           → Val Loss: 0.4251
Epoch 22/40 — Train Loss: 0.7689 — Train Acc: 73.38%
           → Val Loss: 0.3938
Epoch 23/40 — Train Loss: 0.7685 — Train Acc: 73.31%
           → Val Loss: 0.4084
Epoch 24/40 — Train Loss: 0.7578 — Train Acc: 73.36%
           → Val Loss: 0.4371
Epoch 25/40 — Train Loss: 0.7550 — Train Acc: 73.42%
           → Val Loss: 0.4805
Epoch 26/40 — Train Loss: 0.7556 — Train Acc: 73.68%
           → Val Loss: 0.3948
Epoch 27/40 — Train Loss: 0.7400 — Train Acc: 74.44%
           → Val Loss: 0.4120
⏹️ Early stopping at epoch 27
✅ Accuracy: 85.24%

🔍 Testing combination: {'lr': 0.002004622569625198, 'batch_size': 32, 'dropout': 0.3095778760666471, 'conv_channels': [32, 64, 128], 'linear_size': 192, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.1639 — Train Acc: 32.74%
           → Val Loss: 1.1874
Epoch 2/40 — Train Loss: 1.4221 — Train Acc: 51.38%
           → Val Loss: 0.8579
Epoch 3/40 — Train Loss: 1.2308 — Train Acc: 57.31%
           → Val Loss: 0.6947
Epoch 4/40 — Train Loss: 1.1168 — Train Acc: 61.16%
           → Val Loss: 0.6093
Epoch 5/40 — Train Loss: 1.0284 — Train Acc: 63.98%
           → Val Loss: 0.5772
Epoch 6/40 — Train Loss: 0.9774 — Train Acc: 65.89%
           → Val Loss: 0.5180
Epoch 7/40 — Train Loss: 0.9318 — Train Acc: 67.50%
           → Val Loss: 0.5013
Epoch 8/40 — Train Loss: 0.8917 — Train Acc: 68.35%
           → Val Loss: 0.4394
Epoch 9/40 — Train Loss: 0.8550 — Train Acc: 69.87%
           → Val Loss: 0.4474
Epoch 10/40 — Train Loss: 0.8313 — Train Acc: 70.93%
           → Val Loss: 0.4269
Epoch 11/40 — Train Loss: 0.8135 — Train Acc: 71.44%
           → Val Loss: 0.4215
Epoch 12/40 — Train Loss: 0.7825 — Train Acc: 71.87%
           → Val Loss: 0.3863
Epoch 13/40 — Train Loss: 0.7646 — Train Acc: 73.00%
           → Val Loss: 0.3984
Epoch 14/40 — Train Loss: 0.7514 — Train Acc: 73.37%
           → Val Loss: 0.3868
Epoch 15/40 — Train Loss: 0.7468 — Train Acc: 73.72%
           → Val Loss: 0.3424
Epoch 16/40 — Train Loss: 0.7267 — Train Acc: 74.26%
           → Val Loss: 0.3716
Epoch 17/40 — Train Loss: 0.7119 — Train Acc: 74.78%
           → Val Loss: 0.3845
Epoch 18/40 — Train Loss: 0.7033 — Train Acc: 74.97%
           → Val Loss: 0.3302
Epoch 19/40 — Train Loss: 0.6971 — Train Acc: 75.60%
           → Val Loss: 0.3361
Epoch 20/40 — Train Loss: 0.6914 — Train Acc: 75.59%
           → Val Loss: 0.3291
Epoch 21/40 — Train Loss: 0.6863 — Train Acc: 75.68%
           → Val Loss: 0.3342
Epoch 22/40 — Train Loss: 0.6693 — Train Acc: 76.19%
           → Val Loss: 0.3279
Epoch 23/40 — Train Loss: 0.6595 — Train Acc: 76.61%
           → Val Loss: 0.3101
Epoch 24/40 — Train Loss: 0.6682 — Train Acc: 76.38%
           → Val Loss: 0.3308
Epoch 25/40 — Train Loss: 0.6599 — Train Acc: 76.73%
           → Val Loss: 0.3072
Epoch 26/40 — Train Loss: 0.6489 — Train Acc: 77.36%
           → Val Loss: 0.3016
Epoch 27/40 — Train Loss: 0.6434 — Train Acc: 77.32%
           → Val Loss: 0.3056
Epoch 28/40 — Train Loss: 0.6493 — Train Acc: 76.94%
           → Val Loss: 0.3119
⏹️ Early stopping at epoch 28
✅ Accuracy: 88.37%

🔍 Testing combination: {'lr': 0.0027585671686901204, 'batch_size': 8, 'dropout': 0.4423750544646695, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'sigmoid', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.7299 — Train Acc: 2.73%
           → Val Loss: 3.6657
Epoch 2/40 — Train Loss: 3.7294 — Train Acc: 2.92%
           → Val Loss: 3.6574
Epoch 3/40 — Train Loss: 3.7286 — Train Acc: 2.95%
           → Val Loss: 3.6365
Epoch 4/40 — Train Loss: 3.7256 — Train Acc: 2.75%
           → Val Loss: 3.6985
Epoch 5/40 — Train Loss: 3.7289 — Train Acc: 2.92%
           → Val Loss: 3.6749
Epoch 6/40 — Train Loss: 3.7265 — Train Acc: 3.01%
           → Val Loss: 3.6540
Epoch 7/40 — Train Loss: 3.7274 — Train Acc: 2.98%
           → Val Loss: 3.6824
Epoch 8/40 — Train Loss: 3.7298 — Train Acc: 2.91%
           → Val Loss: 3.7322
⏹️ Early stopping at epoch 8
✅ Accuracy: 2.52%

🔍 Testing combination: {'lr': 0.00021806877744184937, 'batch_size': 64, 'dropout': 0.20619482992617447, 'conv_channels': [32, 64, 128], 'linear_size': 384, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.0894 — Train Acc: 37.89%
           → Val Loss: 0.9811
Epoch 2/40 — Train Loss: 1.0463 — Train Acc: 65.42%
           → Val Loss: 0.5687
Epoch 3/40 — Train Loss: 0.7479 — Train Acc: 74.50%
           → Val Loss: 0.4105
Epoch 4/40 — Train Loss: 0.5969 — Train Acc: 79.31%
           → Val Loss: 0.3537
Epoch 5/40 — Train Loss: 0.5054 — Train Acc: 82.33%
           → Val Loss: 0.2613
Epoch 6/40 — Train Loss: 0.4537 — Train Acc: 84.05%
           → Val Loss: 0.2423
Epoch 7/40 — Train Loss: 0.4073 — Train Acc: 85.80%
           → Val Loss: 0.2294
Epoch 8/40 — Train Loss: 0.3802 — Train Acc: 86.55%
           → Val Loss: 0.2082
Epoch 9/40 — Train Loss: 0.3477 — Train Acc: 87.83%
           → Val Loss: 0.1854
Epoch 10/40 — Train Loss: 0.3148 — Train Acc: 88.92%
           → Val Loss: 0.1736
Epoch 11/40 — Train Loss: 0.3028 — Train Acc: 89.37%
           → Val Loss: 0.1714
Epoch 12/40 — Train Loss: 0.2848 — Train Acc: 90.22%
           → Val Loss: 0.1515
Epoch 13/40 — Train Loss: 0.2659 — Train Acc: 90.73%
           → Val Loss: 0.1616
Epoch 14/40 — Train Loss: 0.2553 — Train Acc: 91.11%
           → Val Loss: 0.1382
Epoch 15/40 — Train Loss: 0.2483 — Train Acc: 91.25%
           → Val Loss: 0.1513
Epoch 16/40 — Train Loss: 0.2247 — Train Acc: 92.10%
           → Val Loss: 0.1205
Epoch 17/40 — Train Loss: 0.2296 — Train Acc: 92.11%
           → Val Loss: 0.1273
Epoch 18/40 — Train Loss: 0.2069 — Train Acc: 92.51%
           → Val Loss: 0.1195
Epoch 19/40 — Train Loss: 0.2061 — Train Acc: 92.93%
           → Val Loss: 0.1086
Epoch 20/40 — Train Loss: 0.1943 — Train Acc: 93.43%
           → Val Loss: 0.1042
Epoch 21/40 — Train Loss: 0.1880 — Train Acc: 93.41%
           → Val Loss: 0.1146
Epoch 22/40 — Train Loss: 0.1902 — Train Acc: 93.21%
           → Val Loss: 0.1171
Epoch 23/40 — Train Loss: 0.1805 — Train Acc: 93.79%
           → Val Loss: 0.1001
Epoch 24/40 — Train Loss: 0.1759 — Train Acc: 93.98%
           → Val Loss: 0.0958
Epoch 25/40 — Train Loss: 0.1675 — Train Acc: 94.33%
           → Val Loss: 0.0934
Epoch 26/40 — Train Loss: 0.1666 — Train Acc: 94.40%
           → Val Loss: 0.1124
Epoch 27/40 — Train Loss: 0.1554 — Train Acc: 94.61%
           → Val Loss: 0.1137
Epoch 28/40 — Train Loss: 0.1527 — Train Acc: 94.69%
           → Val Loss: 0.0912
Epoch 29/40 — Train Loss: 0.1546 — Train Acc: 94.81%
           → Val Loss: 0.0831
Epoch 30/40 — Train Loss: 0.1512 — Train Acc: 94.82%
           → Val Loss: 0.0949
Epoch 31/40 — Train Loss: 0.1488 — Train Acc: 94.93%
           → Val Loss: 0.0761
Epoch 32/40 — Train Loss: 0.1382 — Train Acc: 95.29%
           → Val Loss: 0.0812
Epoch 33/40 — Train Loss: 0.1373 — Train Acc: 95.30%
           → Val Loss: 0.0865
Epoch 34/40 — Train Loss: 0.1351 — Train Acc: 95.51%
           → Val Loss: 0.0763
⏹️ Early stopping at epoch 34
✅ Accuracy: 96.84%

🔍 Testing combination: {'lr': 0.002405509739758666, 'batch_size': 128, 'dropout': 0.49569494612334025, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.5947 — Train Acc: 23.23%
           → Val Loss: 1.3891
Epoch 2/40 — Train Loss: 1.6178 — Train Acc: 46.36%
           → Val Loss: 0.9914
Epoch 3/40 — Train Loss: 1.3825 — Train Acc: 52.93%
           → Val Loss: 0.7492
Epoch 4/40 — Train Loss: 1.2327 — Train Acc: 57.46%
           → Val Loss: 0.6404
Epoch 5/40 — Train Loss: 1.1415 — Train Acc: 60.75%
           → Val Loss: 0.5870
Epoch 6/40 — Train Loss: 1.0622 — Train Acc: 63.27%
           → Val Loss: 0.5276
Epoch 7/40 — Train Loss: 1.0042 — Train Acc: 65.06%
           → Val Loss: 0.5315
Epoch 8/40 — Train Loss: 0.9549 — Train Acc: 66.60%
           → Val Loss: 0.4921
Epoch 9/40 — Train Loss: 0.9183 — Train Acc: 67.71%
           → Val Loss: 0.4424
Epoch 10/40 — Train Loss: 0.8933 — Train Acc: 68.64%
           → Val Loss: 0.4063
Epoch 11/40 — Train Loss: 0.8676 — Train Acc: 69.72%
           → Val Loss: 0.4038
Epoch 12/40 — Train Loss: 0.8473 — Train Acc: 70.18%
           → Val Loss: 0.4074
Epoch 13/40 — Train Loss: 0.8242 — Train Acc: 71.08%
           → Val Loss: 0.3814
Epoch 14/40 — Train Loss: 0.8010 — Train Acc: 71.81%
           → Val Loss: 0.3458
Epoch 15/40 — Train Loss: 0.7834 — Train Acc: 72.46%
           → Val Loss: 0.3639
Epoch 16/40 — Train Loss: 0.7636 — Train Acc: 72.82%
           → Val Loss: 0.3422
Epoch 17/40 — Train Loss: 0.7580 — Train Acc: 73.18%
           → Val Loss: 0.3302
Epoch 18/40 — Train Loss: 0.7465 — Train Acc: 73.90%
           → Val Loss: 0.3370
Epoch 19/40 — Train Loss: 0.7408 — Train Acc: 73.52%
           → Val Loss: 0.3003
Epoch 20/40 — Train Loss: 0.7212 — Train Acc: 74.60%
           → Val Loss: 0.3130
Epoch 21/40 — Train Loss: 0.7172 — Train Acc: 74.61%
           → Val Loss: 0.3104
Epoch 22/40 — Train Loss: 0.6995 — Train Acc: 75.27%
           → Val Loss: 0.3007
Epoch 23/40 — Train Loss: 0.6935 — Train Acc: 75.62%
           → Val Loss: 0.3086
Epoch 24/40 — Train Loss: 0.6849 — Train Acc: 75.70%
           → Val Loss: 0.2920
⏹️ Early stopping at epoch 24
✅ Accuracy: 89.03%

🔍 Testing combination: {'lr': 0.00010197103401578104, 'batch_size': 64, 'dropout': 0.34769106086287993, 'conv_channels': [16, 32, 64], 'linear_size': 192, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.1843 — Train Acc: 10.99%
           → Val Loss: 2.5224
Epoch 2/40 — Train Loss: 2.5680 — Train Acc: 23.91%
           → Val Loss: 1.9728
Epoch 3/40 — Train Loss: 2.1544 — Train Acc: 33.86%
           → Val Loss: 1.5043
Epoch 4/40 — Train Loss: 1.8264 — Train Acc: 42.38%
           → Val Loss: 1.2425
Epoch 5/40 — Train Loss: 1.6160 — Train Acc: 47.80%
           → Val Loss: 1.0796
Epoch 6/40 — Train Loss: 1.4811 — Train Acc: 51.57%
           → Val Loss: 0.9376
Epoch 7/40 — Train Loss: 1.3682 — Train Acc: 54.71%
           → Val Loss: 0.8762
Epoch 8/40 — Train Loss: 1.3094 — Train Acc: 56.34%
           → Val Loss: 0.7986
Epoch 9/40 — Train Loss: 1.2370 — Train Acc: 58.22%
           → Val Loss: 0.7427
Epoch 10/40 — Train Loss: 1.1947 — Train Acc: 60.03%
           → Val Loss: 0.7027
Epoch 11/40 — Train Loss: 1.1511 — Train Acc: 61.09%
           → Val Loss: 0.6771
Epoch 12/40 — Train Loss: 1.1189 — Train Acc: 61.97%
           → Val Loss: 0.6427
Epoch 13/40 — Train Loss: 1.0800 — Train Acc: 63.08%
           → Val Loss: 0.6124
Epoch 14/40 — Train Loss: 1.0533 — Train Acc: 63.84%
           → Val Loss: 0.5904
Epoch 15/40 — Train Loss: 1.0176 — Train Acc: 65.05%
           → Val Loss: 0.5872
Epoch 16/40 — Train Loss: 1.0040 — Train Acc: 65.57%
           → Val Loss: 0.5390
Epoch 17/40 — Train Loss: 0.9717 — Train Acc: 66.71%
           → Val Loss: 0.5604
Epoch 18/40 — Train Loss: 0.9680 — Train Acc: 66.45%
           → Val Loss: 0.5233
Epoch 19/40 — Train Loss: 0.9453 — Train Acc: 67.41%
           → Val Loss: 0.5223
Epoch 20/40 — Train Loss: 0.9131 — Train Acc: 68.25%
           → Val Loss: 0.5007
Epoch 21/40 — Train Loss: 0.9145 — Train Acc: 68.27%
           → Val Loss: 0.5136
Epoch 22/40 — Train Loss: 0.8943 — Train Acc: 68.59%
           → Val Loss: 0.4705
Epoch 23/40 — Train Loss: 0.8799 — Train Acc: 69.53%
           → Val Loss: 0.4602
Epoch 24/40 — Train Loss: 0.8702 — Train Acc: 69.79%
           → Val Loss: 0.4562
Epoch 25/40 — Train Loss: 0.8490 — Train Acc: 69.93%
           → Val Loss: 0.4492
Epoch 26/40 — Train Loss: 0.8427 — Train Acc: 70.56%
           → Val Loss: 0.4207
Epoch 27/40 — Train Loss: 0.8277 — Train Acc: 71.12%
           → Val Loss: 0.4247
Epoch 28/40 — Train Loss: 0.8241 — Train Acc: 71.31%
           → Val Loss: 0.4154
Epoch 29/40 — Train Loss: 0.8036 — Train Acc: 71.67%
           → Val Loss: 0.4091
Epoch 30/40 — Train Loss: 0.8000 — Train Acc: 72.04%
           → Val Loss: 0.4073
Epoch 31/40 — Train Loss: 0.7917 — Train Acc: 72.21%
           → Val Loss: 0.4028
Epoch 32/40 — Train Loss: 0.7782 — Train Acc: 72.52%
           → Val Loss: 0.3950
Epoch 33/40 — Train Loss: 0.7659 — Train Acc: 72.91%
           → Val Loss: 0.3815
Epoch 34/40 — Train Loss: 0.7666 — Train Acc: 73.04%
           → Val Loss: 0.3609
Epoch 35/40 — Train Loss: 0.7573 — Train Acc: 73.36%
           → Val Loss: 0.3742
Epoch 36/40 — Train Loss: 0.7370 — Train Acc: 74.00%
           → Val Loss: 0.3666
Epoch 37/40 — Train Loss: 0.7282 — Train Acc: 74.20%
           → Val Loss: 0.3541
Epoch 38/40 — Train Loss: 0.7324 — Train Acc: 74.38%
           → Val Loss: 0.3434
Epoch 39/40 — Train Loss: 0.7243 — Train Acc: 74.37%
           → Val Loss: 0.3431
Epoch 40/40 — Train Loss: 0.7145 — Train Acc: 74.85%
           → Val Loss: 0.3418
✅ Accuracy: 88.34%

🔍 Testing combination: {'lr': 0.0020142177594998875, 'batch_size': 8, 'dropout': 0.3926571035810738, 'conv_channels': [48, 96, 192], 'linear_size': 192, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.5805 — Train Acc: 3.05%
           → Val Loss: 3.5803
Epoch 2/40 — Train Loss: 3.5788 — Train Acc: 3.03%
           → Val Loss: 3.5799
Epoch 3/40 — Train Loss: 3.5788 — Train Acc: 3.04%
           → Val Loss: 3.5806
Epoch 4/40 — Train Loss: 3.5788 — Train Acc: 3.12%
           → Val Loss: 3.5804
Epoch 5/40 — Train Loss: 3.5790 — Train Acc: 3.08%
           → Val Loss: 3.5791
Epoch 6/40 — Train Loss: 3.5790 — Train Acc: 2.94%
           → Val Loss: 3.5801
⏹️ Early stopping at epoch 6
✅ Accuracy: 2.74%

🔍 Testing combination: {'lr': 0.00362106255043758, 'batch_size': 64, 'dropout': 0.23806360146183844, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.6023 — Train Acc: 2.97%
           → Val Loss: 3.5798
Epoch 2/40 — Train Loss: 3.5786 — Train Acc: 2.89%
           → Val Loss: 3.5795
Epoch 3/40 — Train Loss: 3.5784 — Train Acc: 3.14%
           → Val Loss: 3.5795
Epoch 4/40 — Train Loss: 3.5784 — Train Acc: 2.92%
           → Val Loss: 3.5799
Epoch 5/40 — Train Loss: 3.5784 — Train Acc: 2.85%
           → Val Loss: 3.5795
Epoch 6/40 — Train Loss: 3.5783 — Train Acc: 3.07%
           → Val Loss: 3.5793
⏹️ Early stopping at epoch 6
✅ Accuracy: 2.85%

🔍 Testing combination: {'lr': 0.00033997983244825016, 'batch_size': 64, 'dropout': 0.4719959104777049, 'conv_channels': [16, 32, 64], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.6485 — Train Acc: 22.72%
           → Val Loss: 1.4274
Epoch 2/40 — Train Loss: 1.6595 — Train Acc: 46.01%
           → Val Loss: 0.9883
Epoch 3/40 — Train Loss: 1.3804 — Train Acc: 54.17%
           → Val Loss: 0.8104
Epoch 4/40 — Train Loss: 1.2214 — Train Acc: 58.36%
           → Val Loss: 0.6857
Epoch 5/40 — Train Loss: 1.1212 — Train Acc: 61.30%
           → Val Loss: 0.5941
Epoch 6/40 — Train Loss: 1.0396 — Train Acc: 64.25%
           → Val Loss: 0.5227
Epoch 7/40 — Train Loss: 0.9745 — Train Acc: 65.94%
           → Val Loss: 0.5038
Epoch 8/40 — Train Loss: 0.9230 — Train Acc: 67.48%
           → Val Loss: 0.4796
Epoch 9/40 — Train Loss: 0.8750 — Train Acc: 69.20%
           → Val Loss: 0.4220
Epoch 10/40 — Train Loss: 0.8513 — Train Acc: 70.04%
           → Val Loss: 0.3997
Epoch 11/40 — Train Loss: 0.7993 — Train Acc: 71.55%
           → Val Loss: 0.3893
Epoch 12/40 — Train Loss: 0.7758 — Train Acc: 72.26%
           → Val Loss: 0.3605
Epoch 13/40 — Train Loss: 0.7487 — Train Acc: 73.46%
           → Val Loss: 0.3359
Epoch 14/40 — Train Loss: 0.7127 — Train Acc: 74.56%
           → Val Loss: 0.3227
Epoch 15/40 — Train Loss: 0.6981 — Train Acc: 74.91%
           → Val Loss: 0.3299
Epoch 16/40 — Train Loss: 0.6746 — Train Acc: 75.89%
           → Val Loss: 0.3273
Epoch 17/40 — Train Loss: 0.6639 — Train Acc: 76.38%
           → Val Loss: 0.2810
Epoch 18/40 — Train Loss: 0.6343 — Train Acc: 77.46%
           → Val Loss: 0.2669
Epoch 19/40 — Train Loss: 0.6235 — Train Acc: 77.53%
           → Val Loss: 0.2484
Epoch 20/40 — Train Loss: 0.6035 — Train Acc: 78.44%
           → Val Loss: 0.2514
Epoch 21/40 — Train Loss: 0.5917 — Train Acc: 78.47%
           → Val Loss: 0.2484
Epoch 22/40 — Train Loss: 0.5876 — Train Acc: 78.90%
           → Val Loss: 0.2406
Epoch 23/40 — Train Loss: 0.5633 — Train Acc: 79.65%
           → Val Loss: 0.2444
Epoch 24/40 — Train Loss: 0.5549 — Train Acc: 80.13%
           → Val Loss: 0.2128
Epoch 25/40 — Train Loss: 0.5471 — Train Acc: 80.57%
           → Val Loss: 0.2058
Epoch 26/40 — Train Loss: 0.5301 — Train Acc: 80.67%
           → Val Loss: 0.2152
Epoch 27/40 — Train Loss: 0.5227 — Train Acc: 81.24%
           → Val Loss: 0.1978
Epoch 28/40 — Train Loss: 0.5042 — Train Acc: 81.99%
           → Val Loss: 0.2038
Epoch 29/40 — Train Loss: 0.5056 — Train Acc: 82.00%
           → Val Loss: 0.2033
Epoch 30/40 — Train Loss: 0.5018 — Train Acc: 82.09%
           → Val Loss: 0.2078
Epoch 31/40 — Train Loss: 0.4905 — Train Acc: 82.72%
           → Val Loss: 0.1967
Epoch 32/40 — Train Loss: 0.4653 — Train Acc: 83.31%
           → Val Loss: 0.1762
Epoch 33/40 — Train Loss: 0.4686 — Train Acc: 83.15%
           → Val Loss: 0.1871
Epoch 34/40 — Train Loss: 0.4661 — Train Acc: 83.32%
           → Val Loss: 0.1718
Epoch 35/40 — Train Loss: 0.4526 — Train Acc: 83.85%
           → Val Loss: 0.1743
Epoch 36/40 — Train Loss: 0.4536 — Train Acc: 83.79%
           → Val Loss: 0.1712
Epoch 37/40 — Train Loss: 0.4431 — Train Acc: 84.16%
           → Val Loss: 0.1684
⏹️ Early stopping at epoch 37
✅ Accuracy: 93.69%

🔍 Testing combination: {'lr': 0.00012199628685097639, 'batch_size': 128, 'dropout': 0.46826405136176685, 'conv_channels': [32, 64, 128], 'linear_size': 384, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.0050 — Train Acc: 15.12%
           → Val Loss: 2.1267
Epoch 2/40 — Train Loss: 2.1477 — Train Acc: 35.30%
           → Val Loss: 1.4177
Epoch 3/40 — Train Loss: 1.6851 — Train Acc: 46.93%
           → Val Loss: 1.0264
Epoch 4/40 — Train Loss: 1.4479 — Train Acc: 53.01%
           → Val Loss: 0.8713
Epoch 5/40 — Train Loss: 1.2964 — Train Acc: 57.28%
           → Val Loss: 0.7291
Epoch 6/40 — Train Loss: 1.1945 — Train Acc: 60.31%
           → Val Loss: 0.6810
Epoch 7/40 — Train Loss: 1.1016 — Train Acc: 63.12%
           → Val Loss: 0.6246
Epoch 8/40 — Train Loss: 1.0435 — Train Acc: 64.64%
           → Val Loss: 0.5843
Epoch 9/40 — Train Loss: 0.9845 — Train Acc: 66.55%
           → Val Loss: 0.5421
Epoch 10/40 — Train Loss: 0.9429 — Train Acc: 67.94%
           → Val Loss: 0.5063
Epoch 11/40 — Train Loss: 0.9020 — Train Acc: 68.98%
           → Val Loss: 0.4735
Epoch 12/40 — Train Loss: 0.8707 — Train Acc: 70.03%
           → Val Loss: 0.4247
Epoch 13/40 — Train Loss: 0.8428 — Train Acc: 70.53%
           → Val Loss: 0.4163
Epoch 14/40 — Train Loss: 0.8128 — Train Acc: 72.11%
           → Val Loss: 0.4018
Epoch 15/40 — Train Loss: 0.7857 — Train Acc: 72.79%
           → Val Loss: 0.3856
Epoch 16/40 — Train Loss: 0.7714 — Train Acc: 73.42%
           → Val Loss: 0.3667
Epoch 17/40 — Train Loss: 0.7546 — Train Acc: 73.68%
           → Val Loss: 0.3661
Epoch 18/40 — Train Loss: 0.7263 — Train Acc: 74.92%
           → Val Loss: 0.3434
Epoch 19/40 — Train Loss: 0.7159 — Train Acc: 75.20%
           → Val Loss: 0.3318
Epoch 20/40 — Train Loss: 0.7024 — Train Acc: 75.45%
           → Val Loss: 0.3272
Epoch 21/40 — Train Loss: 0.6830 — Train Acc: 75.97%
           → Val Loss: 0.3196
Epoch 22/40 — Train Loss: 0.6720 — Train Acc: 76.69%
           → Val Loss: 0.3031
Epoch 23/40 — Train Loss: 0.6514 — Train Acc: 77.24%
           → Val Loss: 0.2931
Epoch 24/40 — Train Loss: 0.6416 — Train Acc: 77.38%
           → Val Loss: 0.2727
Epoch 25/40 — Train Loss: 0.6333 — Train Acc: 77.60%
           → Val Loss: 0.2784
Epoch 26/40 — Train Loss: 0.6136 — Train Acc: 78.35%
           → Val Loss: 0.2709
Epoch 27/40 — Train Loss: 0.6129 — Train Acc: 78.56%
           → Val Loss: 0.2600
Epoch 28/40 — Train Loss: 0.5931 — Train Acc: 79.31%
           → Val Loss: 0.2488
Epoch 29/40 — Train Loss: 0.5846 — Train Acc: 79.22%
           → Val Loss: 0.2434
Epoch 30/40 — Train Loss: 0.5756 — Train Acc: 79.84%
           → Val Loss: 0.2416
Epoch 31/40 — Train Loss: 0.5667 — Train Acc: 80.11%
           → Val Loss: 0.2432
Epoch 32/40 — Train Loss: 0.5662 — Train Acc: 80.03%
           → Val Loss: 0.2417
Epoch 33/40 — Train Loss: 0.5505 — Train Acc: 80.49%
           → Val Loss: 0.2569
⏹️ Early stopping at epoch 33
✅ Accuracy: 92.00%

🔍 Testing combination: {'lr': 0.005607625573948235, 'batch_size': 32, 'dropout': 0.21072444363358037, 'conv_channels': [48, 96, 192], 'linear_size': 384, 'activation': 'sigmoid', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.8662 — Train Acc: 2.71%
           → Val Loss: 3.8283
Epoch 2/40 — Train Loss: 3.8684 — Train Acc: 3.01%
           → Val Loss: 3.9147
Epoch 3/40 — Train Loss: 3.8728 — Train Acc: 2.80%
           → Val Loss: 3.8931
Epoch 4/40 — Train Loss: 3.8734 — Train Acc: 2.86%
           → Val Loss: 3.8962
Epoch 5/40 — Train Loss: 3.8740 — Train Acc: 2.85%
           → Val Loss: 3.7092
Epoch 6/40 — Train Loss: 3.8582 — Train Acc: 2.90%
           → Val Loss: 3.7168
Epoch 7/40 — Train Loss: 3.8683 — Train Acc: 2.94%
           → Val Loss: 3.7960
Epoch 8/40 — Train Loss: 3.8755 — Train Acc: 2.78%
           → Val Loss: 3.7377
Epoch 9/40 — Train Loss: 3.8598 — Train Acc: 2.91%
           → Val Loss: 3.7924
Epoch 10/40 — Train Loss: 3.8718 — Train Acc: 2.71%
           → Val Loss: 3.8136
⏹️ Early stopping at epoch 10
✅ Accuracy: 2.99%

🔍 Testing combination: {'lr': 0.0008976378638020268, 'batch_size': 32, 'dropout': 0.4109355077566278, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.1509 — Train Acc: 34.11%
           → Val Loss: 0.9996
Epoch 2/40 — Train Loss: 1.1882 — Train Acc: 59.29%
           → Val Loss: 0.6633
Epoch 3/40 — Train Loss: 0.9719 — Train Acc: 66.26%
           → Val Loss: 0.5329
Epoch 4/40 — Train Loss: 0.8403 — Train Acc: 70.83%
           → Val Loss: 0.4147
Epoch 5/40 — Train Loss: 0.7572 — Train Acc: 73.62%
           → Val Loss: 0.3551
Epoch 6/40 — Train Loss: 0.7130 — Train Acc: 74.94%
           → Val Loss: 0.3622
Epoch 7/40 — Train Loss: 0.6631 — Train Acc: 76.67%
           → Val Loss: 0.2995
Epoch 8/40 — Train Loss: 0.6166 — Train Acc: 78.41%
           → Val Loss: 0.2848
Epoch 9/40 — Train Loss: 0.5933 — Train Acc: 79.28%
           → Val Loss: 0.2752
Epoch 10/40 — Train Loss: 0.5635 — Train Acc: 80.54%
           → Val Loss: 0.2599
Epoch 11/40 — Train Loss: 0.5429 — Train Acc: 80.85%
           → Val Loss: 0.2298
Epoch 12/40 — Train Loss: 0.5290 — Train Acc: 81.42%
           → Val Loss: 0.2375
Epoch 13/40 — Train Loss: 0.5164 — Train Acc: 81.93%
           → Val Loss: 0.2073
Epoch 14/40 — Train Loss: 0.4871 — Train Acc: 82.64%
           → Val Loss: 0.2192
Epoch 15/40 — Train Loss: 0.4886 — Train Acc: 82.85%
           → Val Loss: 0.2090
Epoch 16/40 — Train Loss: 0.4699 — Train Acc: 83.50%
           → Val Loss: 0.2045
Epoch 17/40 — Train Loss: 0.4489 — Train Acc: 84.23%
           → Val Loss: 0.1975
Epoch 18/40 — Train Loss: 0.4397 — Train Acc: 84.55%
           → Val Loss: 0.1887
Epoch 19/40 — Train Loss: 0.4319 — Train Acc: 84.89%
           → Val Loss: 0.1765
Epoch 20/40 — Train Loss: 0.4252 — Train Acc: 84.85%
           → Val Loss: 0.1656
Epoch 21/40 — Train Loss: 0.4207 — Train Acc: 85.55%
           → Val Loss: 0.1751
Epoch 22/40 — Train Loss: 0.4161 — Train Acc: 85.42%
           → Val Loss: 0.1636
Epoch 23/40 — Train Loss: 0.4010 — Train Acc: 85.71%
           → Val Loss: 0.1711
Epoch 24/40 — Train Loss: 0.4046 — Train Acc: 85.83%
           → Val Loss: 0.1769
Epoch 25/40 — Train Loss: 0.3946 — Train Acc: 86.31%
           → Val Loss: 0.1580
⏹️ Early stopping at epoch 25
✅ Accuracy: 93.96%

🔍 Testing combination: {'lr': 0.005731620426505748, 'batch_size': 32, 'dropout': 0.3531326078142447, 'conv_channels': [48, 96, 192], 'linear_size': 192, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.6234 — Train Acc: 3.02%
           → Val Loss: 3.5798
Epoch 2/40 — Train Loss: 3.5793 — Train Acc: 2.96%
           → Val Loss: 3.5802
Epoch 3/40 — Train Loss: 3.5793 — Train Acc: 2.95%
           → Val Loss: 3.5815
Epoch 4/40 — Train Loss: 3.5792 — Train Acc: 3.17%
           → Val Loss: 3.5806
Epoch 5/40 — Train Loss: 3.5793 — Train Acc: 3.10%
           → Val Loss: 3.5798
Epoch 6/40 — Train Loss: 3.5794 — Train Acc: 3.01%
           → Val Loss: 3.5798
⏹️ Early stopping at epoch 6
✅ Accuracy: 2.82%

🔍 Testing combination: {'lr': 0.0001587022628498408, 'batch_size': 64, 'dropout': 0.2988524828886524, 'conv_channels': [48, 96, 192], 'linear_size': 128, 'activation': 'relu', 'kernel_size': 3, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.7810 — Train Acc: 21.44%
           → Val Loss: 1.6530
Epoch 2/40 — Train Loss: 1.8271 — Train Acc: 42.56%
           → Val Loss: 1.1025
Epoch 3/40 — Train Loss: 1.4974 — Train Acc: 51.12%
           → Val Loss: 0.8983
Epoch 4/40 — Train Loss: 1.3323 — Train Acc: 55.71%
           → Val Loss: 0.7773
Epoch 5/40 — Train Loss: 1.1994 — Train Acc: 59.52%
           → Val Loss: 0.7084
Epoch 6/40 — Train Loss: 1.1147 — Train Acc: 62.16%
           → Val Loss: 0.6504
Epoch 7/40 — Train Loss: 1.0345 — Train Acc: 64.50%
           → Val Loss: 0.6115
Epoch 8/40 — Train Loss: 0.9936 — Train Acc: 65.82%
           → Val Loss: 0.5119
Epoch 9/40 — Train Loss: 0.9453 — Train Acc: 67.37%
           → Val Loss: 0.5176
Epoch 10/40 — Train Loss: 0.8998 — Train Acc: 68.81%
           → Val Loss: 0.4767
Epoch 11/40 — Train Loss: 0.8636 — Train Acc: 69.74%
           → Val Loss: 0.4396
Epoch 12/40 — Train Loss: 0.8265 — Train Acc: 71.04%
           → Val Loss: 0.4354
Epoch 13/40 — Train Loss: 0.8043 — Train Acc: 71.65%
           → Val Loss: 0.4090
Epoch 14/40 — Train Loss: 0.7621 — Train Acc: 73.10%
           → Val Loss: 0.3829
Epoch 15/40 — Train Loss: 0.7395 — Train Acc: 73.92%
           → Val Loss: 0.3798
Epoch 16/40 — Train Loss: 0.7271 — Train Acc: 74.63%
           → Val Loss: 0.3611
Epoch 17/40 — Train Loss: 0.6993 — Train Acc: 75.31%
           → Val Loss: 0.3231
Epoch 18/40 — Train Loss: 0.6741 — Train Acc: 76.45%
           → Val Loss: 0.3346
Epoch 19/40 — Train Loss: 0.6636 — Train Acc: 76.25%
           → Val Loss: 0.3303
Epoch 20/40 — Train Loss: 0.6544 — Train Acc: 76.71%
           → Val Loss: 0.3133
Epoch 21/40 — Train Loss: 0.6380 — Train Acc: 77.35%
           → Val Loss: 0.3100
Epoch 22/40 — Train Loss: 0.6173 — Train Acc: 78.19%
           → Val Loss: 0.2967
Epoch 23/40 — Train Loss: 0.6050 — Train Acc: 78.28%
           → Val Loss: 0.2745
Epoch 24/40 — Train Loss: 0.5927 — Train Acc: 79.45%
           → Val Loss: 0.2673
Epoch 25/40 — Train Loss: 0.5755 — Train Acc: 79.59%
           → Val Loss: 0.2552
Epoch 26/40 — Train Loss: 0.5615 — Train Acc: 80.16%
           → Val Loss: 0.2640
Epoch 27/40 — Train Loss: 0.5589 — Train Acc: 80.26%
           → Val Loss: 0.2548
Epoch 28/40 — Train Loss: 0.5436 — Train Acc: 80.72%
           → Val Loss: 0.2575
Epoch 29/40 — Train Loss: 0.5319 — Train Acc: 81.25%
           → Val Loss: 0.2500
Epoch 30/40 — Train Loss: 0.5284 — Train Acc: 81.16%
           → Val Loss: 0.2334
Epoch 31/40 — Train Loss: 0.5212 — Train Acc: 81.79%
           → Val Loss: 0.2259
Epoch 32/40 — Train Loss: 0.5065 — Train Acc: 81.99%
           → Val Loss: 0.2225
Epoch 33/40 — Train Loss: 0.4948 — Train Acc: 82.76%
           → Val Loss: 0.2292
Epoch 34/40 — Train Loss: 0.4948 — Train Acc: 82.52%
           → Val Loss: 0.2092
Epoch 35/40 — Train Loss: 0.4892 — Train Acc: 82.58%
           → Val Loss: 0.2064
Epoch 36/40 — Train Loss: 0.4705 — Train Acc: 83.18%
           → Val Loss: 0.2000
Epoch 37/40 — Train Loss: 0.4628 — Train Acc: 83.48%
           → Val Loss: 0.2095
Epoch 38/40 — Train Loss: 0.4546 — Train Acc: 83.90%
           → Val Loss: 0.2137
Epoch 39/40 — Train Loss: 0.4528 — Train Acc: 83.71%
           → Val Loss: 0.1884
Epoch 40/40 — Train Loss: 0.4482 — Train Acc: 84.31%
           → Val Loss: 0.1942
✅ Accuracy: 93.19%

🔍 Testing combination: {'lr': 0.00010693644868988849, 'batch_size': 32, 'dropout': 0.3946585293722291, 'conv_channels': [48, 96, 192], 'linear_size': 256, 'activation': 'relu', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 — Train Loss: 2.3373 — Train Acc: 31.80%
           → Val Loss: 1.1174
Epoch 2/40 — Train Loss: 1.3491 — Train Acc: 56.28%
           → Val Loss: 0.6701
Epoch 3/40 — Train Loss: 1.0489 — Train Acc: 65.25%
           → Val Loss: 0.5198
Epoch 4/40 — Train Loss: 0.8652 — Train Acc: 70.85%
           → Val Loss: 0.4330
Epoch 5/40 — Train Loss: 0.7490 — Train Acc: 74.24%
           → Val Loss: 0.3659
Epoch 6/40 — Train Loss: 0.6572 — Train Acc: 77.27%
           → Val Loss: 0.3158
Epoch 7/40 — Train Loss: 0.5978 — Train Acc: 79.18%
           → Val Loss: 0.2786
Epoch 8/40 — Train Loss: 0.5602 — Train Acc: 80.47%
           → Val Loss: 0.2496
Epoch 9/40 — Train Loss: 0.5207 — Train Acc: 81.93%
           → Val Loss: 0.2371
Epoch 10/40 — Train Loss: 0.4788 — Train Acc: 83.30%
           → Val Loss: 0.2202
Epoch 11/40 — Train Loss: 0.4505 — Train Acc: 84.60%
           → Val Loss: 0.2044
Epoch 12/40 — Train Loss: 0.4246 — Train Acc: 85.31%
           → Val Loss: 0.1794
Epoch 13/40 — Train Loss: 0.3964 — Train Acc: 86.11%
           → Val Loss: 0.1853
Epoch 14/40 — Train Loss: 0.3901 — Train Acc: 86.40%
           → Val Loss: 0.1684
Epoch 15/40 — Train Loss: 0.3706 — Train Acc: 87.25%
           → Val Loss: 0.1701
Epoch 16/40 — Train Loss: 0.3463 — Train Acc: 87.97%
           → Val Loss: 0.1541
Epoch 17/40 — Train Loss: 0.3439 — Train Acc: 88.08%
           → Val Loss: 0.1431
Epoch 18/40 — Train Loss: 0.3201 — Train Acc: 88.81%
           → Val Loss: 0.1495
Epoch 19/40 — Train Loss: 0.3128 — Train Acc: 89.11%
           → Val Loss: 0.1431
Epoch 20/40 — Train Loss: 0.2959 — Train Acc: 89.83%
           → Val Loss: 0.1207
Epoch 21/40 — Train Loss: 0.2958 — Train Acc: 89.80%
           → Val Loss: 0.1193
Epoch 22/40 — Train Loss: 0.2800 — Train Acc: 90.34%
           → Val Loss: 0.1122
Epoch 23/40 — Train Loss: 0.2715 — Train Acc: 90.91%
           → Val Loss: 0.1219
Epoch 24/40 — Train Loss: 0.2630 — Train Acc: 90.95%
           → Val Loss: 0.1021
Epoch 25/40 — Train Loss: 0.2578 — Train Acc: 91.17%
           → Val Loss: 0.1106
Epoch 26/40 — Train Loss: 0.2530 — Train Acc: 91.35%
           → Val Loss: 0.1212
Epoch 27/40 — Train Loss: 0.2399 — Train Acc: 91.83%
           → Val Loss: 0.0905
Epoch 28/40 — Train Loss: 0.2356 — Train Acc: 91.97%
           → Val Loss: 0.1000
Epoch 29/40 — Train Loss: 0.2277 — Train Acc: 92.34%
           → Val Loss: 0.0929
Epoch 30/40 — Train Loss: 0.2166 — Train Acc: 92.50%
           → Val Loss: 0.0941
Epoch 31/40 — Train Loss: 0.2154 — Train Acc: 92.58%
           → Val Loss: 0.0849
Epoch 32/40 — Train Loss: 0.2156 — Train Acc: 92.83%
           → Val Loss: 0.0938
⏹️ Early stopping at epoch 32
✅ Accuracy: 96.93%

🔍 Testing combination: {'lr': 0.0004883933424704293, 'batch_size': 32, 'dropout': 0.2152662437829637, 'conv_channels': [48, 96, 192], 'linear_size': 128, 'activation': 'sigmoid', 'kernel_size': 5, 'epochs': 40}
Epoch 1/40 — Train Loss: 3.6060 — Train Acc: 3.16%
           → Val Loss: 3.5882
Epoch 2/40 — Train Loss: 3.6022 — Train Acc: 2.96%
           → Val Loss: 3.5851
Epoch 3/40 — Train Loss: 3.5991 — Train Acc: 3.05%
           → Val Loss: 3.5844
=======
🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.07%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 86.62%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 83.47%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.49%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 81.25%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 32, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 82.89%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.41%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 84.41%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 86.60%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.71%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 85.68%

🔍 Testing combination: {'epochs': 5, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3, 'conv_channels': [64, 128, 256]}
✅ Accuracy: 85.13%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [16, 32, 64]}
✅ Accuracy: 85.27%

🔍 Testing combination: {'epochs': 5, 'lr': 0.0005, 'batch_size': 32, 'dropout': 0.2, 'conv_channels': [32, 64, 128]}
✅ Accuracy: 86.40%
>>>>>>> f547d8b26c7d13467fcb7bc5d329bc0f53f3e7f3
